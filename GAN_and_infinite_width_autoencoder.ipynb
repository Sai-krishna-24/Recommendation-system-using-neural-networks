{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiP-qtbUVrx_",
        "outputId": "b8768282-6d77-4f30-c923-687f3e44dca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit--optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit--optimize) (1.10.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit--optimize) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit--optimize) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit--optimize) (1.22.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit--optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit--optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit--optimize\n",
            "Successfully installed pyaml-21.10.1 scikit--optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit--optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvTOkFSpVw54",
        "outputId": "94b89106-0234-425f-ded9-a344cf6d1af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-03 17:05:21--  https://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘data/ml-1m.zip’\n",
            "\n",
            "ml-1m.zip           100%[===================>]   5.64M  35.2MB/s    in 0.2s    \n",
            "\n",
            "2023-05-03 17:05:21 (35.2 MB/s) - ‘data/ml-1m.zip’ saved [5917549/5917549]\n",
            "\n",
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ]
        }
      ],
      "source": [
        "!mkdir -p data/\n",
        "!wget https://files.grouplens.org/datasets/movielens/ml-1m.zip -P data/\n",
        "!cd data/ ; unzip ml-1m.zip ; rm ml-1m.zip ; cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIR06Du6VzGz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "def remap_items(data):\n",
        "    item_map = {}\n",
        "    for user_data in data:\n",
        "        for item, rating, time in user_data:\n",
        "            if item not in item_map: item_map[item] = len(item_map) + 1\n",
        "\n",
        "    for u in range(len(data)):\n",
        "        data[u] = list(map(lambda x: [ item_map[x[0]], x[1], x[2] ], data[u]))\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcznMTJQV3sD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import psutil\n",
        "import pickle\n",
        "import shutil\n",
        "import random\n",
        "import platform\n",
        "import datetime\n",
        "import warnings\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.sparse as sps\n",
        "import multiprocessing as mp\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "# Supress Tensorflow logs\n",
        "os.environ['KMP_WARNINGS'] = '0'\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import skopt\n",
        "from skopt.callbacks import CheckpointSaver\n",
        "from skopt import gp_minimize, dummy_minimize\n",
        "from skopt.space.space import Real, Integer, Categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loWIiE3KV6D7"
      },
      "outputs": [],
      "source": [
        "#creating data with user mapping its items and ratings\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "f=open('/content/data/ml-1m/ratings.dat','r')\n",
        "users,items,ratings=[],[],[]\n",
        "rec=f.readline()\n",
        "while rec:\n",
        "  user,item,rating,timestamp=rec.strip().split('::')\n",
        "  users.append(int(user))\n",
        "  items.append(int(item))\n",
        "  ratings.append(1)\n",
        "  rec=f.readline()\n",
        "min_user=min(users)\n",
        "data=[[]for _ in range(len(users))]\n",
        "for i in range(len(users)):\n",
        "  data[users[i]-min_user].append([items[i],ratings[i]])\n",
        "#creating index array\n",
        "index = [] \n",
        "for user_data in data:\n",
        "    for _ in range(len(user_data)): \n",
        "      index.append(42)\n",
        "#creating indexs for train test validation split\n",
        "i = 0\n",
        "l=len(data)\n",
        "for user in range(l):\n",
        "    first_split_point = int(0.8 * len(data[user]))\n",
        "    second_split_point = int(0.9 * len(data[user]))\n",
        "\n",
        "    indices = np.arange(len(data[user]))\n",
        "    np.random.shuffle(indices)\n",
        "    for timestep, (item, rating) in enumerate(data[user]):\n",
        "        if len(data[user]) < 3: index[i] = -1\n",
        "        else:\n",
        "            if timestep == indices[0]: index[i] = 2\n",
        "            else:\n",
        "                if timestep in indices[:first_split_point]: index[i] = 0\n",
        "                elif timestep in indices[first_split_point:second_split_point]: index[i] = 1\n",
        "                else:index[i] = 2\n",
        "        i += 1\n",
        "\n",
        "assert i == len(index)\n",
        "complete_data_stats = None\n",
        "valid_users=set()\n",
        "valid_items=set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6EsDQrZV8Wd",
        "outputId": "d44ff974-1804-44ad-d353-109159c8d35d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0, 1193,    1],\n",
              "       [   0,  661,    1],\n",
              "       [   0,  914,    1],\n",
              "       ...,\n",
              "       [6039,  562,    1],\n",
              "       [6039, 1096,    1],\n",
              "       [6039, 1097,    1]])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#creating data of total user item rating in dictionary saving into as total data compressed file\n",
        "path='/content/data/ml-1m'\n",
        "\n",
        "flat_data = []\n",
        "for u in range(len(data)):\n",
        "    flat_data += list(map(lambda x: [ u ] + x,data[u]))\n",
        "flat_data = np.array(flat_data)\n",
        "shape = [ len(flat_data) ]\n",
        "os.makedirs(path, exist_ok = True)\n",
        "data=flat_data\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv8bUWr_WABl",
        "outputId": "f1304ad5-0cc7-4cd5-d330-6cd43a8d1b7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 0 ... 0 0 2] [[   0 1193    1]\n",
            " [   0  661    1]\n",
            " [   0  914    1]\n",
            " ...\n",
            " [6039  562    1]\n",
            " [6039 1096    1]\n",
            " [6039 1097    1]]\n",
            "[1 1 0 ... 0 0 2] [[   0 1104    1]\n",
            " [   0  639    1]\n",
            " [   0  853    1]\n",
            " ...\n",
            " [6039  548    1]\n",
            " [6039 1024    1]\n",
            " [6039 1025    1]]\n",
            "# users: 6040\n",
            "# items: 3706\n",
            "# interactions: 791718\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i,(user,item,rating) in enumerate(data):\n",
        "  valid_users.add(user)\n",
        "  valid_items.add(item)\n",
        "user_map = dict(zip(list(valid_users), list(range(len(valid_users)))))\n",
        "item_map=dict(zip(list(valid_items),list(range(len(valid_items)))))\n",
        "new_data, new_index = [], []\n",
        "index = np.array(index, dtype = np.int32)\n",
        "print(index,data)\n",
        "for at, (u, i, r) in enumerate(data):\n",
        "  if index[at] == -1: continue\n",
        "  new_data.append([ user_map[u], item_map[i], r ])\n",
        "  new_index.append(index[at])\n",
        "data = np.array(new_data, dtype = np.int32)\n",
        "index = np.array(new_index, dtype = np.int32)\n",
        "print(index,data)\n",
        "def select(data, index, index_val):\n",
        "  final = data[np.where(index == index_val)[0]]\n",
        "  final[:, 2] = 1.0\n",
        "  return final.astype(np.int32)\n",
        "\n",
        "ret = {\n",
        "  'item_map': item_map,\n",
        "  'train':  select(data, index, 0),\n",
        "  'val': select(data, index, 1),\n",
        "  'test': select(data, index, 2)\n",
        "}\n",
        "\n",
        "num_users = int(max(data[:, 0]) + 1)\n",
        "num_items = len(item_map)\n",
        "\n",
        "\n",
        "ret.update({\n",
        "    'num_users': num_users,\n",
        "    'num_items': num_items,\n",
        "    'num_interactions': len(ret['train']),\n",
        "})\n",
        "\n",
        "print(\"# users:\", num_users)\n",
        "print(\"# items:\", num_items)\n",
        "print(\"# interactions:\", len(ret['train']))\n",
        "def make_user_history(arr):\n",
        "    ret = [ set() for _ in range(num_users) ]\n",
        "    for u, i, r in arr:\n",
        "        ret[int(u)].add(int(i))\n",
        "    return ret\n",
        "\n",
        "ret['train_positive_set'] = make_user_history(ret['train'])\n",
        "ret['val_positive_set'] = make_user_history(ret['val'])\n",
        "ret['test_positive_set'] = make_user_history(ret['test'])\n",
        "\n",
        "ret['train_matrix'] = csr_matrix(\n",
        "    ( np.ones(ret['train'].shape[0]), (ret['train'][:, 0].astype(np.int32), ret['train'][:, 1].astype(np.int32)) ),\n",
        "    shape = (num_users, num_items)\n",
        ")\n",
        "\n",
        "ret['val_matrix'] = csr_matrix(\n",
        "    ( np.ones(ret['val'].shape[0]), (ret['val'][:, 0].astype(np.int32), ret['val'][:, 1].astype(np.int32)) ),\n",
        "    shape = (num_users, num_items)\n",
        ")\n",
        "ret['test_matrix'] = csr_matrix(\n",
        "    ( np.ones(ret['test'].shape[0]), (ret['test'][:, 0].astype(np.int32), ret['test'][:, 1].astype(np.int32)) ),\n",
        "    shape = (num_users, num_items)\n",
        ")\n",
        "ret.update({\n",
        "    'num_users': num_users,\n",
        "    'num_items': num_items,\n",
        "    'num_interactions': len(ret['train']),\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHx74UBNDQkI"
      },
      "outputs": [],
      "source": [
        "ret['negatives'] = [ set() for _ in range(num_users) ]\n",
        "for u in range(num_users):\n",
        "    while len(ret['negatives'][u]) < 50:\n",
        "        rand_item = np.random.randint(0, num_items)\n",
        "        if rand_item in ret['train_positive_set'][u]: continue\n",
        "        if rand_item in ret['test_positive_set'][u]: continue\n",
        "        ret['negatives'][u].add(rand_item)\n",
        "    ret['negatives'][u] = list(ret['negatives'][u])\n",
        "ret['negatives'] = np.array(ret['negatives'], dtype=np.int32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGmN5NVMWCTS"
      },
      "outputs": [],
      "source": [
        "URM_train=ret['train_matrix']\n",
        "URM_test=ret['test_matrix']\n",
        "URM_validation=ret['val_matrix']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_Tz5lb_WE9E",
        "outputId": "a6776c55-95ad-49ed-f44f-b77c090d5a77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oXbdL5YgWI9C"
      },
      "outputs": [],
      "source": [
        "def average_precision(is_relevant, pos_items):\n",
        "\n",
        "    if len(is_relevant) == 0:\n",
        "        a_p = 0.0\n",
        "    else:\n",
        "        p_at_k = is_relevant * np.cumsum(is_relevant, dtype=np.float32) / (1 + np.arange(is_relevant.shape[0]))\n",
        "        a_p = np.sum(p_at_k) / np.min([pos_items.shape[0], is_relevant.shape[0]])\n",
        "\n",
        "    assert 0 <= a_p <= 1, a_p\n",
        "    return a_p\n",
        "class Metrics_Object(object):\n",
        "    \"\"\"\n",
        "    Abstract class that should be used as superclass of all metrics requiring an object, therefore a state, to be computed\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def add_recommendations(self, recommended_items_ids):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_metric_value(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def merge_with_other(self, other_metric_object):\n",
        "        raise NotImplementedError()\n",
        "class MAP(Metrics_Object):\n",
        "    \"\"\"\n",
        "    Mean Average Precision, defined as the mean of the AveragePrecision over all users\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MAP, self).__init__()\n",
        "        self.cumulative_AP = 0.0\n",
        "        self.n_users = 0\n",
        "\n",
        "    def add_recommendations(self, is_relevant, pos_items):\n",
        "        self.cumulative_AP += average_precision(is_relevant, pos_items)\n",
        "        self.n_users += 1\n",
        "\n",
        "    def get_metric_value(self):\n",
        "        return self.cumulative_AP/self.n_users\n",
        "\n",
        "    def merge_with_other(self, other_metric_object):\n",
        "        assert other_metric_object is MAP, \"MAP: attempting to merge with a metric object of different type\"\n",
        "\n",
        "        self.cumulative_AP += other_metric_object.cumulative_AP\n",
        "        self.n_users += other_metric_object.n_users\n",
        "def precision(is_relevant):\n",
        "\n",
        "    if len(is_relevant) == 0:\n",
        "        precision_score = 0.0\n",
        "    else:\n",
        "        precision_score = np.sum(is_relevant, dtype=np.float32) / len(is_relevant)\n",
        "\n",
        "    assert 0 <= precision_score <= 1, precision_score\n",
        "    return precision_score\n",
        "def rmse(all_items_predicted_ratings, relevant_items, relevant_items_rating):\n",
        "\n",
        "    relevant_items_error = (all_items_predicted_ratings[relevant_items]-relevant_items_rating)**2\n",
        "\n",
        "    finite_prediction_mask = np.isfinite(relevant_items_error)\n",
        "\n",
        "    if finite_prediction_mask.sum() == 0:\n",
        "        rmse = np.nan\n",
        "\n",
        "    else:\n",
        "        relevant_items_error = relevant_items_error[finite_prediction_mask]\n",
        "\n",
        "        squared_error = np.sum(relevant_items_error)\n",
        "\n",
        "\n",
        "        mean_squared_error = squared_error/finite_prediction_mask.sum()\n",
        "        rmse = np.sqrt(mean_squared_error)\n",
        "\n",
        "    return rmse\n",
        "\n",
        "\n",
        "def recall(is_relevant, pos_items):\n",
        "\n",
        "    recall_score = np.sum(is_relevant, dtype=np.float32) / pos_items.shape[0]\n",
        "\n",
        "    assert 0 <= recall_score <= 1, recall_score\n",
        "    return recall_score\n",
        "def ndcg(ranked_list, pos_items, relevance=None, at=None):\n",
        "\n",
        "    if relevance is None:\n",
        "        relevance = np.ones_like(pos_items)\n",
        "    assert len(relevance) == pos_items.shape[0]\n",
        "\n",
        "    it2rel = {it: r for it, r in zip(pos_items, relevance)}\n",
        "\n",
        "    rank_scores = np.asarray([it2rel.get(it, 0.0) for it in ranked_list[:at]], dtype=np.float32)\n",
        "\n",
        "    ideal_dcg = dcg(np.sort(relevance)[::-1])\n",
        "\n",
        "    rank_dcg = dcg(rank_scores)\n",
        "\n",
        "    if rank_dcg == 0.0:\n",
        "        return 0.0\n",
        "\n",
        "    ndcg_ = rank_dcg / ideal_dcg\n",
        "    return ndcg_\n",
        "\n",
        "\n",
        "def dcg(scores):\n",
        "    return np.sum(np.divide(np.power(2, scores) - 1, np.log(np.arange(scores.shape[0], dtype=np.float32) + 2)),\n",
        "                  dtype=np.float32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CzvJtOVWKDX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sps\n",
        "import time, sys, copy\n",
        "\n",
        "from enum import Enum\n",
        "class EvaluatorMetrics(Enum):\n",
        "\n",
        "    PRECISION = \"PRECISION\"\n",
        "    RECALL = \"RECALL\"\n",
        "    MAP = \"MAP\"\n",
        "    NDCG = \"NDCG\"\n",
        "    F1 = \"F1\"\n",
        "    HIT_RATE = \"HIT_RATE\"\n",
        "    RMSE = \"RMSE\"\n",
        "\n",
        "\n",
        "\n",
        "def create_empty_metrics_dict(n_items, n_users, URM_train, ignore_items, ignore_users, cutoff, diversity_similarity_object):\n",
        "\n",
        "    empty_dict = {}\n",
        "\n",
        "    for metric in EvaluatorMetrics:\n",
        "\n",
        "        if metric == EvaluatorMetrics.MAP:\n",
        "            empty_dict[metric.value] = MAP()\n",
        "\n",
        "        else:\n",
        "            empty_dict[metric.value] = 0.0\n",
        "\n",
        "    return  empty_dict\n",
        "\n",
        "def get_result_string(results_run, n_decimals=7):\n",
        "\n",
        "    output_str = \"\"\n",
        "\n",
        "    for cutoff in results_run.keys():\n",
        "\n",
        "        results_run_current_cutoff = results_run[cutoff]\n",
        "\n",
        "        output_str += \"CUTOFF: {} - \".format(cutoff)\n",
        "\n",
        "        for metric in results_run_current_cutoff.keys():\n",
        "            output_str += \"{}: {:.{n_decimals}f}, \".format(metric, results_run_current_cutoff[metric], n_decimals = n_decimals)\n",
        "\n",
        "        output_str += \"\\n\"\n",
        "\n",
        "    return output_str\n",
        "\n",
        "\n",
        "\n",
        "class Evaluator(object):\n",
        "    \"\"\"Abstract Evaluator\"\"\"\n",
        "\n",
        "    EVALUATOR_NAME = \"Evaluator_Base_Class\"\n",
        "\n",
        "    def __init__(self, URM_test_list, cutoff_list, minRatingsPerUser=1, exclude_seen=np.bool_(True),\n",
        "                        diversity_object = None,\n",
        "                        ignore_items = None,\n",
        "                        ignore_users = None):\n",
        "\n",
        "        super(Evaluator, self).__init__()\n",
        "\n",
        "\n",
        "\n",
        "        if ignore_items is None:\n",
        "            self.ignore_items_flag = False\n",
        "            self.ignore_items_ID = np.array([])\n",
        "        else:\n",
        "            print(\"Ignoring {} Items\".format(len(ignore_items)))\n",
        "            self.ignore_items_flag = True\n",
        "            self.ignore_items_ID = np.array(ignore_items)\n",
        "\n",
        "        self.cutoff_list = cutoff_list.copy()\n",
        "        self.max_cutoff = max(self.cutoff_list)\n",
        "\n",
        "        self.minRatingsPerUser = minRatingsPerUser\n",
        "        self.exclude_seen = exclude_seen\n",
        "\n",
        "        if not isinstance(URM_test_list, list):\n",
        "            self.URM_test = URM_test_list.copy()\n",
        "            URM_test_list = [URM_test_list]\n",
        "        else:\n",
        "            raise ValueError(\"List of URM_test not supported\")\n",
        "\n",
        "        self.diversity_object = diversity_object\n",
        "\n",
        "        self.n_users, self.n_items = URM_test_list[0].shape\n",
        "\n",
        "        self.URM_test_list = []\n",
        "        usersToEvaluate_mask = np.zeros(self.n_users, dtype=np.bool)\n",
        "\n",
        "        for URM_test in URM_test_list:\n",
        "\n",
        "            URM_test = sps.csr_matrix(URM_test)\n",
        "            self.URM_test_list.append(URM_test)\n",
        "\n",
        "            rows = URM_test.indptr\n",
        "            numRatings = np.ediff1d(rows)\n",
        "            new_mask = numRatings >= minRatingsPerUser\n",
        "\n",
        "            usersToEvaluate_mask = np.logical_or(usersToEvaluate_mask, new_mask)\n",
        "\n",
        "        self.usersToEvaluate = np.arange(self.n_users)[usersToEvaluate_mask]\n",
        "\n",
        "\n",
        "        if ignore_users is not None:\n",
        "            print(\"Ignoring {} Users\".format(len(ignore_users)))\n",
        "            self.ignore_users_ID = np.array(ignore_users)\n",
        "            self.usersToEvaluate = set(self.usersToEvaluate) - set(ignore_users)\n",
        "        else:\n",
        "            self.ignore_users_ID = np.array([])\n",
        "\n",
        "\n",
        "        self.usersToEvaluate = list(self.usersToEvaluate)\n",
        "\n",
        "    def get_user_relevant_items(self, user_id):\n",
        "\n",
        "        assert self.URM_test.getformat() == \"csr\", \"Evaluator_Base_Class: URM_test is not CSR, this will cause errors in getting relevant items\"\n",
        "\n",
        "        return self.URM_test.indices[self.URM_test.indptr[user_id]:self.URM_test.indptr[user_id+1]]\n",
        "\n",
        "\n",
        "    def get_user_test_ratings(self, user_id):\n",
        "\n",
        "        assert self.URM_test.getformat() == \"csr\", \"Evaluator_Base_Class: URM_test is not CSR, this will cause errors in relevant items ratings\"\n",
        "\n",
        "        return self.URM_test.data[self.URM_test.indptr[user_id]:self.URM_test.indptr[user_id+1]]\n",
        "\n",
        "\n",
        "\n",
        "class EvaluatorHoldout(Evaluator):\n",
        "    \"\"\"EvaluatorHoldout\"\"\"\n",
        "\n",
        "    EVALUATOR_NAME = \"EvaluatorHoldout\"\n",
        "\n",
        "    def __init__(self, URM_test_list, cutoff_list, minRatingsPerUser=1, exclude_seen=np.bool_(True),\n",
        "                 diversity_object = None,\n",
        "                 ignore_items = None,\n",
        "                 ignore_users = None):\n",
        "\n",
        "\n",
        "        super(EvaluatorHoldout, self).__init__(URM_test_list, cutoff_list,\n",
        "                                               diversity_object = diversity_object,\n",
        "                                               minRatingsPerUser=minRatingsPerUser, exclude_seen=exclude_seen,\n",
        "                                               ignore_items = ignore_items, ignore_users = ignore_users)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _run_evaluation_on_selected_users(self, recommender_object, usersToEvaluate, block_size = None):\n",
        "\n",
        "\n",
        "        if block_size is None:\n",
        "            block_size = min(1000, int(1e8/self.n_items))\n",
        "\n",
        "\n",
        "\n",
        "        start_time = time.time()\n",
        "        start_time_print = time.time()\n",
        "\n",
        "\n",
        "        results_dict = {}\n",
        "\n",
        "        for cutoff in self.cutoff_list:\n",
        "            results_dict[cutoff] = create_empty_metrics_dict(self.n_items, self.n_users,\n",
        "                                                             URM_train,\n",
        "                                                             self.ignore_items_ID,\n",
        "                                                             self.ignore_users_ID,\n",
        "                                                             cutoff,\n",
        "                                                             self.diversity_object)\n",
        "\n",
        "        n_users_evaluated = 0\n",
        "\n",
        "        # Start from -block_size to ensure it to be 0 at the first block\n",
        "        user_batch_start = 0\n",
        "        user_batch_end = 0\n",
        "\n",
        "        while user_batch_start < len(self.usersToEvaluate):\n",
        "\n",
        "            user_batch_end = user_batch_start + block_size\n",
        "            user_batch_end = min(user_batch_end, len(usersToEvaluate))\n",
        "\n",
        "            test_user_batch_array = np.array(usersToEvaluate[user_batch_start:user_batch_end])\n",
        "            user_batch_start = user_batch_end\n",
        "\n",
        "            recommended_items_batch_list, scores_batch = recommender_object.recommend(test_user_batch_array,\n",
        "                                                                      remove_seen_flag=self.exclude_seen,\n",
        "                                                                      cutoff = self.max_cutoff,\n",
        "                                                                      remove_top_pop_flag=False,\n",
        "                                                                      remove_CustomItems_flag=self.ignore_items_flag,\n",
        "                                                                      return_scores = True\n",
        "                                                                     )\n",
        "\n",
        "\n",
        "            assert len(recommended_items_batch_list) == len(test_user_batch_array), \"{}: recommended_items_batch_list contained recommendations for {} users, expected was {}\".format(\n",
        "                self.EVALUATOR_NAME, len(recommended_items_batch_list), len(test_user_batch_array))\n",
        "\n",
        "            assert scores_batch.shape[0] == len(test_user_batch_array), \"{}: scores_batch contained scores for {} users, expected was {}\".format(\n",
        "                self.EVALUATOR_NAME, scores_batch.shape[0], len(test_user_batch_array))\n",
        "\n",
        "            assert scores_batch.shape[1] == self.n_items, \"{}: scores_batch contained scores for {} items, expected was {}\".format(\n",
        "                self.EVALUATOR_NAME, scores_batch.shape[1], self.n_items)\n",
        "\n",
        "\n",
        "            for batch_user_index in range(len(recommended_items_batch_list)):\n",
        "\n",
        "                test_user = test_user_batch_array[batch_user_index]\n",
        "\n",
        "                relevant_items = self.get_user_relevant_items(test_user)\n",
        "                relevant_items_rating = self.get_user_test_ratings(test_user)\n",
        "\n",
        "                all_items_predicted_ratings = scores_batch[batch_user_index]\n",
        "                user_rmse = rmse(all_items_predicted_ratings, relevant_items, relevant_items_rating)\n",
        "\n",
        "                # Being the URM CSR, the indices are the non-zero column indexes\n",
        "                recommended_items = recommended_items_batch_list[batch_user_index]\n",
        "                is_relevant = np.in1d(recommended_items, relevant_items, assume_unique=True)\n",
        "\n",
        "                n_users_evaluated += 1\n",
        "\n",
        "                for cutoff in self.cutoff_list:\n",
        "\n",
        "                    results_current_cutoff = results_dict[cutoff]\n",
        "\n",
        "                    is_relevant_current_cutoff = is_relevant[0:cutoff]\n",
        "                    recommended_items_current_cutoff = recommended_items[0:cutoff]\n",
        "\n",
        "                    results_current_cutoff[EvaluatorMetrics.PRECISION.value]            += precision(is_relevant_current_cutoff)\n",
        "                    results_current_cutoff[EvaluatorMetrics.RECALL.value]               += recall(is_relevant_current_cutoff, relevant_items)\n",
        "                    results_current_cutoff[EvaluatorMetrics.NDCG.value]                 += ndcg(recommended_items_current_cutoff, relevant_items, relevance=self.get_user_test_ratings(test_user), at=cutoff)\n",
        "                    results_current_cutoff[EvaluatorMetrics.HIT_RATE.value]             += is_relevant_current_cutoff.sum()\n",
        "                    results_current_cutoff[EvaluatorMetrics.RMSE.value]                 += user_rmse\n",
        "                    results_current_cutoff[EvaluatorMetrics.MAP.value].add_recommendations(is_relevant_current_cutoff, relevant_items)\n",
        "                    \n",
        "\n",
        "                    sys.stdout.flush()\n",
        "                    sys.stderr.flush()\n",
        "\n",
        "                    start_time_print = time.time()\n",
        "\n",
        "\n",
        "\n",
        "        return results_dict, n_users_evaluated\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def evaluateRecommender(self, recommender_object):\n",
        "\n",
        "        if self.ignore_items_flag:\n",
        "            recommender_object.set_items_to_ignore(self.ignore_items_ID)\n",
        "\n",
        "\n",
        "\n",
        "        results_dict, n_users_evaluated = self._run_evaluation_on_selected_users(recommender_object, self.usersToEvaluate)\n",
        "\n",
        "\n",
        "        if (n_users_evaluated > 0):\n",
        "\n",
        "            for cutoff in self.cutoff_list:\n",
        "\n",
        "                results_current_cutoff = results_dict[cutoff]\n",
        "\n",
        "                for key in results_current_cutoff.keys():\n",
        "\n",
        "                    value = results_current_cutoff[key]\n",
        "\n",
        "                    if isinstance(value, Metrics_Object):\n",
        "                        results_current_cutoff[key] = value.get_metric_value()\n",
        "                    else:\n",
        "                        results_current_cutoff[key] = value/n_users_evaluated\n",
        "\n",
        "                precision_ = results_current_cutoff[EvaluatorMetrics.PRECISION.value]\n",
        "                recall_ = results_current_cutoff[EvaluatorMetrics.RECALL.value]\n",
        "\n",
        "                if precision_ + recall_ != 0:\n",
        "                    results_current_cutoff[EvaluatorMetrics.F1.value] = 2 * (precision_ * recall_) / (precision_ + recall_)\n",
        "\n",
        "\n",
        "        else:\n",
        "            print(\"WARNING: No users had a sufficient number of relevant items\")\n",
        "\n",
        "\n",
        "\n",
        "        results_run_string = get_result_string(results_dict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if self.ignore_items_flag:\n",
        "            recommender_object.reset_items_to_ignore()\n",
        "\n",
        "\n",
        "        return (results_dict, results_run_string)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAH9ZSZkWV4j",
        "outputId": "42707c35-6c40-43c7-f9a1-1857fb57668c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-6ceb33196298>:90: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  usersToEvaluate_mask = np.zeros(self.n_users, dtype=np.bool)\n"
          ]
        }
      ],
      "source": [
        "evaluatorValidation = EvaluatorHoldout(URM_validation,[5,10,50,80,100,500],exclude_seen=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2F3Dr6oWNJl"
      },
      "outputs": [],
      "source": [
        "class EarlyStoppingScheduler(object):\n",
        "    def __init__(self, model, evaluator, metrics=['PRECISION', 'RECALL', 'MAP', 'NDCG'], freq=1, allow_worse=5):\n",
        "        self.model = model\n",
        "        self.evaluator = evaluator\n",
        "        self.metrics = metrics\n",
        "        self.freq = freq\n",
        "        self.best_scores = np.zeros(len(metrics))\n",
        "        self.allow_worse = allow_worse\n",
        "        self.worse_left = allow_worse\n",
        "        self.scores = []\n",
        "\n",
        "    def score(self, epoch):\n",
        "        if epoch % self.freq == 0:\n",
        "            results_dic, _ = self.evaluator.evaluateRecommender(self.model) #TODO: dependent on recommender interface\n",
        "            curr_scores = np.array([results_dic[5][m] for m in self.metrics])\n",
        "            self.scores.append(curr_scores)\n",
        "            if np.all(np.less_equal(curr_scores, self.best_scores)):\n",
        "                if self.worse_left > 0:\n",
        "                    self.worse_left -= 1\n",
        "                else:\n",
        "                    self.model.stop_fit()\n",
        "                    self.model.load_model()\n",
        "            else:\n",
        "                self.best_scores = curr_scores\n",
        "                self.worse_left = self.allow_worse\n",
        "                self.model.save_current_model()\n",
        "\n",
        "    def __call__(self, epoch):\n",
        "        self.score(epoch)\n",
        "\n",
        "    def load_best(self):\n",
        "        self.model.load_model()\n",
        "\n",
        "    def get_scores(self):\n",
        "        return self.scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frpGwlgTWPX7"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "class BaseRecommender(object):\n",
        "\n",
        "    RECOMMENDER_NAME = \"Recommender_Base_Class\"\n",
        "\n",
        "    def __init__(self, URM_train):\n",
        "\n",
        "        super(BaseRecommender, self).__init__()\n",
        "\n",
        "        self.URM_train = URM_train.copy()\n",
        "        self.URM_train.eliminate_zeros()\n",
        "\n",
        "        self.n_users, self.n_items = self.URM_train.shape\n",
        "\n",
        "        self.normalize = False\n",
        "\n",
        "        self.filterTopPop = False\n",
        "        self.filterTopPop_ItemsID = np.array([], dtype=np.int)\n",
        "\n",
        "        self.items_to_ignore_flag = False\n",
        "        self.items_to_ignore_ID = np.array([], dtype=np.int)\n",
        "\n",
        "        self._cold_user_mask = np.ediff1d(self.URM_train.indptr) == 0\n",
        "\n",
        "        if self._cold_user_mask.any():\n",
        "            print(\"{}: Detected {} ({:.2f} %) cold users.\".format(\n",
        "                self.RECOMMENDER_NAME, self._cold_user_mask.sum(), self._cold_user_mask.sum()/len(self._cold_user_mask)*100))\n",
        "\n",
        "\n",
        "\n",
        "    def _get_cold_user_mask(self):\n",
        "        return self._cold_user_mask\n",
        "\n",
        "    def get_URM_train(self):\n",
        "        return self.URM_train.copy()\n",
        "\n",
        "    def set_URM_train(self, URM_train_new, **kwargs):\n",
        "\n",
        "        assert self.URM_train.shape == URM_train_new.shape, \"{}: set_URM_train old and new URM train have different shapes\".format(self.RECOMMENDER_NAME)\n",
        "\n",
        "        if len(kwargs)>0:\n",
        "            print(\"{}: set_URM_train keyword arguments not supported for this recommender class. Received: {}\".format(self.RECOMMENDER_NAME, kwargs))\n",
        "\n",
        "        self.URM_train = URM_train_new.copy()\n",
        "        self.URM_train.eliminate_zeros()\n",
        "\n",
        "        self._cold_user_mask = np.ediff1d(self.URM_train.indptr) == 0\n",
        "\n",
        "        if self._cold_user_mask.any():\n",
        "            print(\"{}: Detected {} ({:.2f} %) cold users.\".format(\n",
        "                self.RECOMMENDER_NAME, self._cold_user_mask.sum(), self._cold_user_mask.sum()/len(self._cold_user_mask)*100))\n",
        "\n",
        "\n",
        "\n",
        "    def set_items_to_ignore(self, items_to_ignore):\n",
        "\n",
        "        self.items_to_ignore_flag = True\n",
        "        self.items_to_ignore_ID = np.array(items_to_ignore, dtype=np.int)\n",
        "\n",
        "    def reset_items_to_ignore(self):\n",
        "\n",
        "        self.items_to_ignore_flag = False\n",
        "        self.items_to_ignore_ID = np.array([], dtype=np.int)\n",
        "\n",
        "\n",
        "    def _remove_TopPop_on_scores(self, scores_batch):\n",
        "        scores_batch[:, self.filterTopPop_ItemsID] = -np.inf\n",
        "        return scores_batch\n",
        "\n",
        "\n",
        "    def _remove_CustomItems_on_scores(self, scores_batch):\n",
        "        scores_batch[:, self.items_to_ignore_ID] = -np.inf\n",
        "        return scores_batch\n",
        "\n",
        "\n",
        "    def _remove_seen_on_scores(self, user_id, scores):\n",
        "\n",
        "        assert self.URM_train.getformat() == \"csr\", \"Recommender_Base_Class: URM_train is not CSR, this will cause errors in filtering seen items\"\n",
        "\n",
        "        if user_id >= len(self.URM_train.indptr):\n",
        "          seen = []\n",
        "        elif user_id + 1 >= len(self.URM_train.indptr):\n",
        "          seen = self.URM_train.indices[self.URM_train.indptr[user_id]:]\n",
        "        else:\n",
        "          seen = self.URM_train.indices[self.URM_train.indptr[user_id]:self.URM_train.indptr[user_id + 1]]\n",
        "        scores[seen] = -np.inf\n",
        "        return scores\n",
        "\n",
        "\n",
        "\n",
        "    def recommend(self, user_id_array, cutoff = None, remove_seen_flag=True, items_to_compute = None,\n",
        "                  remove_top_pop_flag = False, remove_CustomItems_flag = False, return_scores = False):\n",
        "\n",
        "        if np.isscalar(user_id_array):\n",
        "            user_id_array = np.atleast_1d(user_id_array)\n",
        "            single_user = True\n",
        "        else:\n",
        "            single_user = False\n",
        "\n",
        "\n",
        "        if cutoff is None:\n",
        "            cutoff = self.URM_train.shape[1] - 1\n",
        "\n",
        "        scores_batch = self._compute_item_score(user_id_array, items_to_compute=items_to_compute)\n",
        "\n",
        "        for user_index in range(len(user_id_array)):\n",
        "\n",
        "            user_id = user_id_array[user_index]\n",
        "\n",
        "            if remove_seen_flag:\n",
        "                scores_batch[user_index,:] = self._remove_seen_on_scores(user_id, scores_batch[user_index, :])\n",
        "\n",
        "\n",
        "        if remove_top_pop_flag:\n",
        "            scores_batch = self._remove_TopPop_on_scores(scores_batch)\n",
        "\n",
        "        if remove_CustomItems_flag:\n",
        "            scores_batch = self._remove_CustomItems_on_scores(scores_batch)\n",
        "        relevant_items_partition = (-scores_batch).argpartition(cutoff, axis=1)[:,0:cutoff]\n",
        "        relevant_items_partition_original_value = scores_batch[np.arange(scores_batch.shape[0])[:, None], relevant_items_partition]\n",
        "        relevant_items_partition_sorting = np.argsort(-relevant_items_partition_original_value, axis=1)\n",
        "        ranking = relevant_items_partition[np.arange(relevant_items_partition.shape[0])[:, None], relevant_items_partition_sorting]\n",
        "\n",
        "        ranking_list = [None] * ranking.shape[0]\n",
        "\n",
        "        for user_index in range(len(user_id_array)):\n",
        "            user_recommendation_list = ranking[user_index]\n",
        "            user_item_scores = scores_batch[user_index, user_recommendation_list]\n",
        "\n",
        "            not_inf_scores_mask = np.logical_not(np.isinf(user_item_scores))\n",
        "\n",
        "            user_recommendation_list = user_recommendation_list[not_inf_scores_mask]\n",
        "            ranking_list[user_index] = user_recommendation_list.tolist()\n",
        "\n",
        "        if single_user:\n",
        "            ranking_list = ranking_list[0]\n",
        "\n",
        "\n",
        "        if return_scores:\n",
        "            return ranking_list, scores_batch\n",
        "\n",
        "        else:\n",
        "            return ranking_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06IWGiAkWrLw"
      },
      "outputs": [],
      "source": [
        "class GANMF(BaseRecommender):\n",
        "\n",
        "    def __init__(self, URM_train, mode='user', verbose=False, seed=1234, is_experiment=False):\n",
        "\n",
        "        if mode not in ['user', 'item']:\n",
        "            raise ValueError('Accepted training modes are `user` and `item`. Given was {}.', mode)\n",
        "\n",
        "        self.mode = mode\n",
        "        if self.mode == 'item':\n",
        "            self.URM_train = URM_train.T.tocsr()\n",
        "        else:\n",
        "            self.URM_train = URM_train\n",
        "        self.num_users, self.num_items = self.URM_train.shape\n",
        "        self.config = None\n",
        "        self.seed = seed\n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def build(self, num_factors=10, emb_dim=32):\n",
        "        glorot_uniform = tf.glorot_uniform_initializer()\n",
        "\n",
        "        def autoencoder(input_data):\n",
        "            with tf.variable_scope('autoencoder', reuse=tf.AUTO_REUSE):\n",
        "                encoding = tf.layers.dense(input_data, units=emb_dim, kernel_initializer=glorot_uniform, name='encoding')\n",
        "                decoding = tf.layers.dense(encoding, units=self.num_items, kernel_initializer=glorot_uniform, name='decoding')\n",
        "            loss = tf.losses.mean_squared_error(input_data, decoding)\n",
        "            return encoding, loss\n",
        "\n",
        "        def generator(condition):\n",
        "            with tf.variable_scope('generator', reuse=tf.AUTO_REUSE):\n",
        "                user_embeddings = tf.get_variable(shape=[self.num_users, num_factors], trainable=True,\n",
        "                                initializer=glorot_uniform, name='user_embeddings')\n",
        "                item_embeddings = tf.get_variable(shape=[self.num_items, num_factors], trainable=True,\n",
        "                                initializer=glorot_uniform, name='item_embeddings')\n",
        "            condition = tf.where(tf.less(condition, self.num_users-1), condition, tf.zeros_like(condition))\n",
        "            user_lookup = tf.nn.embedding_lookup(user_embeddings, condition)\n",
        "            item_factors = tf.layers.dense(user_lookup, units=num_factors, activation=None, kernel_initializer=glorot_uniform, name='item_factors')\n",
        "            #fake_data = tf.matmul(item_factors[:, :, None], item_embeddings[None, :, :], transpose_b=True)[:, 0, :]\n",
        "\n",
        "            fake_data = tf.matmul(tf.squeeze(user_lookup, axis=1), item_embeddings, transpose_b=True)\n",
        "            return fake_data\n",
        "\n",
        "        self.autoencoder, self.generator = autoencoder, generator\n",
        "\n",
        "    def fit(self, num_factors=10, emb_dim=32, epochs=300, batch_size=32, d_lr=1e-4, g_lr=1e-4, d_steps=1, g_steps=1,\n",
        "            d_reg=0, g_reg=0, m=1, recon_coefficient=1e-2, allow_worse=None, freq=None, metrics=['MAP','NDCG','RMSE'], sample_every=None,\n",
        "            validation_evaluator=None, validation_set=None):\n",
        "\n",
        "        # Construct the model config\n",
        "        self.config = dict(locals())\n",
        "        del self.config['self']\n",
        "\n",
        "        # First clear the session to save GPU memory\n",
        "        tf.reset_default_graph()\n",
        "        # Set fixed seed for the TF graph\n",
        "        tf.set_random_seed(self.seed)\n",
        "\n",
        "        self.build(num_factors, emb_dim)\n",
        "\n",
        "        # Create optimizers\n",
        "        opt_gen = tf.train.AdamOptimizer(learning_rate=g_lr)\n",
        "        opt_disc = tf.train.AdamOptimizer(learning_rate=d_lr)\n",
        "\n",
        "        # placeholders\n",
        "        real_profile = tf.placeholder(dtype=tf.float32, shape=[None, self.num_items])\n",
        "        self.user_id = tf.placeholder(dtype=tf.int32, shape=[None, 1])\n",
        "\n",
        "        # generator ops\n",
        "        self.fake_profile = self.generator(self.user_id)\n",
        "\n",
        "        # autoencoder ops\n",
        "        real_encoding, real_recon_loss = self.autoencoder(real_profile)\n",
        "        fake_encoding, fake_recon_loss = self.autoencoder(self.fake_profile)\n",
        "\n",
        "        # model parameters\n",
        "        self.dvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='autoencoder')\n",
        "        self.gvars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
        "\n",
        "        with tf.variable_scope('dvars_best', reuse=tf.AUTO_REUSE):\n",
        "            self.dvars_best = []\n",
        "            for idx, var in enumerate(self.dvars):\n",
        "                self.dvars_best.append(tf.get_variable('dva_r' + str(idx), shape=var.get_shape(), trainable=False))\n",
        "        with tf.variable_scope('gvars_best', reuse=tf.AUTO_REUSE):\n",
        "            self.gvars_best = []\n",
        "            for idx, var in enumerate(self.gvars):\n",
        "                self.gvars_best.append(tf.get_variable('gvar_' + str(idx), shape=var.get_shape(), trainable=False))\n",
        "\n",
        "        # losses\n",
        "        dloss = real_recon_loss + tf.maximum(0.0, m * real_recon_loss - fake_recon_loss) + \\\n",
        "                d_reg * tf.add_n([tf.nn.l2_loss(var) for var in self.dvars])\n",
        "        gloss = (1 - recon_coefficient) * fake_recon_loss + \\\n",
        "                recon_coefficient * tf.losses.mean_squared_error(real_encoding, fake_encoding) + \\\n",
        "                g_reg * tf.add_n([tf.nn.l2_loss(var) for var in self.gvars])\n",
        "\n",
        "        # update ops\n",
        "        dtrain = opt_disc.minimize(dloss, var_list=self.dvars)\n",
        "        gtrain = opt_gen.minimize(gloss, var_list=self.gvars)\n",
        "\n",
        "        self.sess = tf.Session()\n",
        "        self.sess.run(tf.initialize_all_variables())\n",
        "\n",
        "        self._stop_training = False\n",
        "        if validation_evaluator is not None:\n",
        "            early_stop = EarlyStoppingScheduler(self, evaluator=validation_evaluator, allow_worse=allow_worse,\n",
        "                                                freq=freq, metrics=metrics)\n",
        "\n",
        "        all_users = np.array(range(self.num_users))\n",
        "        step = batch_size\n",
        "\n",
        "        train_g_loss = []\n",
        "        train_d_loss = []\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Starting training...')\n",
        "\n",
        "        t_start = time.time()\n",
        "        e_start = time.time()\n",
        "\n",
        "        epoch = 1\n",
        "\n",
        "        pbar = tqdm.tqdm(total=epochs, initial=1)\n",
        "\n",
        "        while not self._stop_training and epoch < epochs + 1:\n",
        "            batch_d_loss = []\n",
        "            batch_g_loss = []\n",
        "            np.random.shuffle(all_users)\n",
        "            for _ in range(d_steps):\n",
        "                start_idx = 0\n",
        "                while start_idx < len(all_users):\n",
        "                    end_idx = start_idx + step\n",
        "                    if end_idx > len(all_users):\n",
        "                        end_idx = len(all_users)\n",
        "\n",
        "                    uids = all_users[start_idx: end_idx]\n",
        "                    real_histories = self.URM_train[uids].toarray()\n",
        "\n",
        "                    _, _dloss = self.sess.run([dtrain, dloss], {real_profile: real_histories, self.user_id: uids.reshape(-1, 1)})\n",
        "                    batch_d_loss.append(_dloss)\n",
        "                    start_idx = end_idx\n",
        "\n",
        "            for _ in range(g_steps):\n",
        "                start_idx = 0\n",
        "                while start_idx < len(all_users):\n",
        "                    end_idx = start_idx + step\n",
        "                    if end_idx > len(all_users):\n",
        "                        end_idx = len(all_users)\n",
        "\n",
        "                    uids = all_users[start_idx: end_idx]\n",
        "                    real_histories = self.URM_train[uids].toarray()\n",
        "                    _, _gloss = self.sess.run([gtrain, gloss], {real_profile: real_histories, self.user_id: uids.reshape(-1, 1)})\n",
        "                    batch_g_loss.append(_gloss)\n",
        "                    start_idx = end_idx\n",
        "\n",
        "            mean_epoch_g_loss = np.mean(batch_g_loss)\n",
        "            mean_epoch_d_loss = np.mean(batch_d_loss)\n",
        "\n",
        "            train_g_loss.append(mean_epoch_g_loss)\n",
        "            train_d_loss.append(mean_epoch_d_loss)\n",
        "\n",
        "            if validation_set is not None and sample_every is not None and epoch % sample_every == 0:\n",
        "                t_end = time.time()\n",
        "                total = t_end-e_start\n",
        "                print('Epoch : {:d}. Total: {:.2f} secs, {:.2f} secs/epoch.'.format(epoch, total, total/sample_every))\n",
        "                if self.mode == 'item':\n",
        "                    self.URM_train = self.URM_train.T.tocsr()\n",
        "                _, results_run_string = validation_evaluator.evaluateRecommender(self)\n",
        "                if self.mode == 'item':\n",
        "                    self.URM_train = self.URM_train.T.tocsr()\n",
        "                print(results_run_string)\n",
        "                e_start = time.time()\n",
        "\n",
        "            if validation_evaluator is not None:\n",
        "                if self.mode == 'item':\n",
        "                    self.URM_train = self.URM_train.T.tocsr()\n",
        "                early_stop(epoch)\n",
        "                if self.mode == 'item':\n",
        "                    self.URM_train = self.URM_train.T.tocsr()\n",
        "\n",
        "                if self._stop_training:\n",
        "                    print('Training stopped, epoch:', epoch)\n",
        "\n",
        "            epoch += 1\n",
        "            pbar.update()\n",
        "        pbar.close()\n",
        "\n",
        "        t_end = time.time()\n",
        "        if self.verbose:\n",
        "            print('Training took {:.2f} seconds'.format(t_end - t_start))\n",
        "\n",
        "        if self.mode == 'item':\n",
        "            self.URM_train = self.URM_train.T.tocsr()\n",
        "\n",
        "        return epoch\n",
        "\n",
        "    def stop_fit(self):\n",
        "        self._stop_training = True\n",
        "\n",
        "    def save_current_model(self):\n",
        "        for idx, var in enumerate(self.dvars):\n",
        "            self.sess.run(self.dvars_best[idx].assign(var))\n",
        "        for idx, var in enumerate(self.gvars):\n",
        "            self.sess.run(self.gvars_best[idx].assign(var))\n",
        "\n",
        "    def load_model(self):\n",
        "        for idx, var in enumerate(self.dvars_best):\n",
        "            self.sess.run(self.dvars[idx].assign(var))\n",
        "        for idx, var in enumerate(self.gvars_best):\n",
        "            self.sess.run(self.gvars[idx].assign(var))\n",
        "\n",
        "    def _compute_item_score(self, user_id_array, items_to_compute=None):\n",
        "        if self.mode == 'item':\n",
        "            predictions = self.sess.run(self.fake_profile, {self.user_id: np.array(range(self.num_users)).reshape(-1, 1)})\n",
        "            return predictions.transpose()[user_id_array]\n",
        "        else:\n",
        "            return self.sess.run(self.fake_profile, {self.user_id: user_id_array.reshape(-1, 1)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbwbkzqB4HUT"
      },
      "outputs": [],
      "source": [
        "import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-XvRPhV3vyP",
        "outputId": "31b05fea-0219-4850-a5a8-d198463c8ac2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-6ceb33196298>:90: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  usersToEvaluate_mask = np.zeros(self.n_users, dtype=np.bool)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/tf_should_use.py:243: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
            "Instructions for updating:\n",
            "Use `tf.global_variables_initializer` instead.\n",
            "  3%|▎         | 10/300 [00:50<18:03,  3.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 10. Total: 51.21 secs, 5.12 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.0071854, RECALL: 0.0020573, MAP: 0.0033860, NDCG: 0.0027812, F1: 0.0031988, HIT_RATE: 0.0359272, RMSE: 0.9991374, \n",
            "CUTOFF: 10 - PRECISION: 0.0073510, RECALL: 0.0039277, MAP: 0.0024869, NDCG: 0.0042759, F1: 0.0051198, HIT_RATE: 0.0735099, RMSE: 0.9991374, \n",
            "CUTOFF: 20 - PRECISION: 0.0070199, RECALL: 0.0075796, MAP: 0.0019842, NDCG: 0.0064913, F1: 0.0072890, HIT_RATE: 0.1403974, RMSE: 0.9991374, \n",
            "CUTOFF: 50 - PRECISION: 0.0066159, RECALL: 0.0173308, MAP: 0.0018877, NDCG: 0.0112384, F1: 0.0095762, HIT_RATE: 0.3307947, RMSE: 0.9991374, \n",
            "CUTOFF: 80 - PRECISION: 0.0064031, RECALL: 0.0272266, MAP: 0.0020357, NDCG: 0.0152082, F1: 0.0103680, HIT_RATE: 0.5122517, RMSE: 0.9991374, \n",
            "CUTOFF: 100 - PRECISION: 0.0063626, RECALL: 0.0340909, MAP: 0.0021463, NDCG: 0.0177370, F1: 0.0107237, HIT_RATE: 0.6362583, RMSE: 0.9991374, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|▋         | 20/300 [02:59<20:34,  4.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 20. Total: 87.00 secs, 8.70 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.0315232, RECALL: 0.0079215, MAP: 0.0172365, NDCG: 0.0124541, F1: 0.0126613, HIT_RATE: 0.1576159, RMSE: 0.9865058, \n",
            "CUTOFF: 10 - PRECISION: 0.0293212, RECALL: 0.0146492, MAP: 0.0121911, NDCG: 0.0179367, F1: 0.0195373, HIT_RATE: 0.2932119, RMSE: 0.9865058, \n",
            "CUTOFF: 20 - PRECISION: 0.0270778, RECALL: 0.0278191, MAP: 0.0094649, NDCG: 0.0261808, F1: 0.0274435, HIT_RATE: 0.5415563, RMSE: 0.9865058, \n",
            "CUTOFF: 50 - PRECISION: 0.0229636, RECALL: 0.0602300, MAP: 0.0089193, NDCG: 0.0419242, F1: 0.0332501, HIT_RATE: 1.1481788, RMSE: 0.9865058, \n",
            "CUTOFF: 80 - PRECISION: 0.0204967, RECALL: 0.0868345, MAP: 0.0095877, NDCG: 0.0528017, F1: 0.0331650, HIT_RATE: 1.6397351, RMSE: 0.9865058, \n",
            "CUTOFF: 100 - PRECISION: 0.0196589, RECALL: 0.1044701, MAP: 0.0101109, NDCG: 0.0594884, F1: 0.0330909, HIT_RATE: 1.9658940, RMSE: 0.9865058, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 10%|█         | 30/300 [05:08<20:03,  4.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 30. Total: 87.30 secs, 8.73 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.0652980, RECALL: 0.0163212, MAP: 0.0385596, NDCG: 0.0255162, F1: 0.0261150, HIT_RATE: 0.3264901, RMSE: 0.9809765, \n",
            "CUTOFF: 10 - PRECISION: 0.0605795, RECALL: 0.0297379, MAP: 0.0282510, NDCG: 0.0367923, F1: 0.0398928, HIT_RATE: 0.6057947, RMSE: 0.9809765, \n",
            "CUTOFF: 20 - PRECISION: 0.0541060, RECALL: 0.0531449, MAP: 0.0225287, NDCG: 0.0518949, F1: 0.0536211, HIT_RATE: 1.0821192, RMSE: 0.9809765, \n",
            "CUTOFF: 50 - PRECISION: 0.0442682, RECALL: 0.1094818, MAP: 0.0215076, NDCG: 0.0802434, F1: 0.0630447, HIT_RATE: 2.2134106, RMSE: 0.9809765, \n",
            "CUTOFF: 80 - PRECISION: 0.0385969, RECALL: 0.1545798, MAP: 0.0232654, NDCG: 0.0991261, F1: 0.0617703, HIT_RATE: 3.0877483, RMSE: 0.9809765, \n",
            "CUTOFF: 100 - PRECISION: 0.0359735, RECALL: 0.1806124, MAP: 0.0245152, NDCG: 0.1092684, F1: 0.0599971, HIT_RATE: 3.5973510, RMSE: 0.9809765, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 40/300 [07:18<19:19,  4.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 40. Total: 87.12 secs, 8.71 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.0983113, RECALL: 0.0323313, MAP: 0.0605347, NDCG: 0.0463930, F1: 0.0486600, HIT_RATE: 0.4915563, RMSE: 0.9659895, \n",
            "CUTOFF: 10 - PRECISION: 0.0891556, RECALL: 0.0582398, MAP: 0.0462056, NDCG: 0.0655927, F1: 0.0704555, HIT_RATE: 0.8915563, RMSE: 0.9659895, \n",
            "CUTOFF: 20 - PRECISION: 0.0770861, RECALL: 0.0975037, MAP: 0.0394787, NDCG: 0.0889856, F1: 0.0861010, HIT_RATE: 1.5417219, RMSE: 0.9659895, \n",
            "CUTOFF: 50 - PRECISION: 0.0595927, RECALL: 0.1873141, MAP: 0.0401531, NDCG: 0.1302829, F1: 0.0904192, HIT_RATE: 2.9796358, RMSE: 0.9659895, \n",
            "CUTOFF: 80 - PRECISION: 0.0508733, RECALL: 0.2539676, MAP: 0.0434233, NDCG: 0.1563217, F1: 0.0847667, HIT_RATE: 4.0698675, RMSE: 0.9659895, \n",
            "CUTOFF: 100 - PRECISION: 0.0467003, RECALL: 0.2920379, MAP: 0.0453357, NDCG: 0.1697777, F1: 0.0805239, HIT_RATE: 4.6700331, RMSE: 0.9659895, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 50/300 [09:49<22:27,  5.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 50. Total: 108.90 secs, 10.89 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.1259272, RECALL: 0.0479817, MAP: 0.0791479, NDCG: 0.0645929, F1: 0.0694869, HIT_RATE: 0.6296358, RMSE: 0.9441212, \n",
            "CUTOFF: 10 - PRECISION: 0.1120033, RECALL: 0.0826355, MAP: 0.0622776, NDCG: 0.0894838, F1: 0.0951038, HIT_RATE: 1.1200331, RMSE: 0.9441212, \n",
            "CUTOFF: 20 - PRECISION: 0.0953477, RECALL: 0.1399099, MAP: 0.0551903, NDCG: 0.1211379, F1: 0.1134083, HIT_RATE: 1.9069536, RMSE: 0.9441212, \n",
            "CUTOFF: 50 - PRECISION: 0.0710364, RECALL: 0.2533763, MAP: 0.0572674, NDCG: 0.1712076, F1: 0.1109633, HIT_RATE: 3.5518212, RMSE: 0.9441212, \n",
            "CUTOFF: 80 - PRECISION: 0.0591080, RECALL: 0.3306892, MAP: 0.0614448, NDCG: 0.2004160, F1: 0.1002900, HIT_RATE: 4.7286424, RMSE: 0.9441212, \n",
            "CUTOFF: 100 - PRECISION: 0.0537732, RECALL: 0.3737924, MAP: 0.0637882, NDCG: 0.2153783, F1: 0.0940207, HIT_RATE: 5.3773179, RMSE: 0.9441212, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 20%|██        | 60/300 [12:10<18:37,  4.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 60. Total: 88.21 secs, 8.82 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.1424172, RECALL: 0.0575503, MAP: 0.0921130, NDCG: 0.0768015, F1: 0.0819749, HIT_RATE: 0.7120861, RMSE: 0.9204737, \n",
            "CUTOFF: 10 - PRECISION: 0.1273510, RECALL: 0.1015764, MAP: 0.0739974, NDCG: 0.1071847, F1: 0.1130128, HIT_RATE: 1.2735099, RMSE: 0.9204737, \n",
            "CUTOFF: 20 - PRECISION: 0.1063328, RECALL: 0.1658448, MAP: 0.0665836, NDCG: 0.1422715, F1: 0.1295826, HIT_RATE: 2.1266556, RMSE: 0.9204737, \n",
            "CUTOFF: 50 - PRECISION: 0.0778079, RECALL: 0.2918494, MAP: 0.0696960, NDCG: 0.1970989, F1: 0.1228608, HIT_RATE: 3.8903974, RMSE: 0.9204737, \n",
            "CUTOFF: 80 - PRECISION: 0.0640522, RECALL: 0.3749869, MAP: 0.0744946, NDCG: 0.2281678, F1: 0.1094150, HIT_RATE: 5.1241722, RMSE: 0.9204737, \n",
            "CUTOFF: 100 - PRECISION: 0.0578344, RECALL: 0.4174093, MAP: 0.0770354, NDCG: 0.2430642, F1: 0.1015926, HIT_RATE: 5.7834437, RMSE: 0.9204737, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 70/300 [14:21<17:29,  4.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 70. Total: 88.13 secs, 8.81 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.1576490, RECALL: 0.0671500, MAP: 0.1028398, NDCG: 0.0874792, F1: 0.0941830, HIT_RATE: 0.7882450, RMSE: 0.8987433, \n",
            "CUTOFF: 10 - PRECISION: 0.1382947, RECALL: 0.1148230, MAP: 0.0831698, NDCG: 0.1201078, F1: 0.1254706, HIT_RATE: 1.3829470, RMSE: 0.8987433, \n",
            "CUTOFF: 20 - PRECISION: 0.1142467, RECALL: 0.1848313, MAP: 0.0756406, NDCG: 0.1578544, F1: 0.1412098, HIT_RATE: 2.2849338, RMSE: 0.8987433, \n",
            "CUTOFF: 50 - PRECISION: 0.0826258, RECALL: 0.3169376, MAP: 0.0793664, NDCG: 0.2154256, F1: 0.1310792, HIT_RATE: 4.1312914, RMSE: 0.8987433, \n",
            "CUTOFF: 80 - PRECISION: 0.0675662, RECALL: 0.4026014, MAP: 0.0846087, NDCG: 0.2474315, F1: 0.1157130, HIT_RATE: 5.4052980, RMSE: 0.8987433, \n",
            "CUTOFF: 100 - PRECISION: 0.0607781, RECALL: 0.4452355, MAP: 0.0873014, NDCG: 0.2624955, F1: 0.1069560, HIT_RATE: 6.0778146, RMSE: 0.8987433, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 80/300 [16:31<16:34,  4.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 80. Total: 88.19 secs, 8.82 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.1668212, RECALL: 0.0737252, MAP: 0.1101809, NDCG: 0.0946701, F1: 0.1022582, HIT_RATE: 0.8341060, RMSE: 0.8801374, \n",
            "CUTOFF: 10 - PRECISION: 0.1466391, RECALL: 0.1251921, MAP: 0.0902186, NDCG: 0.1296691, F1: 0.1350695, HIT_RATE: 1.4663907, RMSE: 0.8801374, \n",
            "CUTOFF: 20 - PRECISION: 0.1200993, RECALL: 0.1988547, MAP: 0.0824254, NDCG: 0.1692916, F1: 0.1497540, HIT_RATE: 2.4019868, RMSE: 0.8801374, \n",
            "CUTOFF: 50 - PRECISION: 0.0865728, RECALL: 0.3379822, MAP: 0.0868982, NDCG: 0.2297440, F1: 0.1378388, HIT_RATE: 4.3286424, RMSE: 0.8801374, \n",
            "CUTOFF: 80 - PRECISION: 0.0706147, RECALL: 0.4249029, MAP: 0.0925255, NDCG: 0.2625402, F1: 0.1211032, HIT_RATE: 5.6491722, RMSE: 0.8801374, \n",
            "CUTOFF: 100 - PRECISION: 0.0633874, RECALL: 0.4685567, MAP: 0.0953794, NDCG: 0.2779642, F1: 0.1116681, HIT_RATE: 6.3387417, RMSE: 0.8801374, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 90/300 [18:39<15:32,  4.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 90. Total: 86.66 secs, 8.67 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.1764238, RECALL: 0.0803112, MAP: 0.1166084, NDCG: 0.1010817, F1: 0.1103769, HIT_RATE: 0.8821192, RMSE: 0.8641971, \n",
            "CUTOFF: 10 - PRECISION: 0.1531954, RECALL: 0.1341832, MAP: 0.0958508, NDCG: 0.1373932, F1: 0.1430604, HIT_RATE: 1.5319536, RMSE: 0.8641971, \n",
            "CUTOFF: 20 - PRECISION: 0.1254553, RECALL: 0.2112157, MAP: 0.0879827, NDCG: 0.1788010, F1: 0.1574126, HIT_RATE: 2.5091060, RMSE: 0.8641971, \n",
            "CUTOFF: 50 - PRECISION: 0.0901954, RECALL: 0.3544465, MAP: 0.0931852, NDCG: 0.2413303, F1: 0.1437986, HIT_RATE: 4.5097682, RMSE: 0.8641971, \n",
            "CUTOFF: 80 - PRECISION: 0.0733113, RECALL: 0.4429860, MAP: 0.0991243, NDCG: 0.2748738, F1: 0.1258030, HIT_RATE: 5.8649007, RMSE: 0.8641971, \n",
            "CUTOFF: 100 - PRECISION: 0.0657268, RECALL: 0.4871484, MAP: 0.1021335, NDCG: 0.2905827, F1: 0.1158262, HIT_RATE: 6.5726821, RMSE: 0.8641971, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 100/300 [20:47<14:46,  4.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 100. Total: 86.38 secs, 8.64 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.1813245, RECALL: 0.0833969, MAP: 0.1217718, NDCG: 0.1051201, F1: 0.1142477, HIT_RATE: 0.9066225, RMSE: 0.8504799, \n",
            "CUTOFF: 10 - PRECISION: 0.1582285, RECALL: 0.1403503, MAP: 0.1005997, NDCG: 0.1433413, F1: 0.1487541, HIT_RATE: 1.5822848, RMSE: 0.8504799, \n",
            "CUTOFF: 20 - PRECISION: 0.1300828, RECALL: 0.2204409, MAP: 0.0929786, NDCG: 0.1866274, F1: 0.1636156, HIT_RATE: 2.6016556, RMSE: 0.8504799, \n",
            "CUTOFF: 50 - PRECISION: 0.0933543, RECALL: 0.3666895, MAP: 0.0987059, NDCG: 0.2507844, F1: 0.1488208, HIT_RATE: 4.6677152, RMSE: 0.8504799, \n",
            "CUTOFF: 80 - PRECISION: 0.0758278, RECALL: 0.4591623, MAP: 0.1050666, NDCG: 0.2857299, F1: 0.1301604, HIT_RATE: 6.0662252, RMSE: 0.8504799, \n",
            "CUTOFF: 100 - PRECISION: 0.0680066, RECALL: 0.5032623, MAP: 0.1082704, NDCG: 0.3017035, F1: 0.1198216, HIT_RATE: 6.8006623, RMSE: 0.8504799, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 110/300 [22:54<14:03,  4.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 110. Total: 86.26 secs, 8.63 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.1858609, RECALL: 0.0866250, MAP: 0.1254246, NDCG: 0.1084498, F1: 0.1181727, HIT_RATE: 0.9293046, RMSE: 0.8384327, \n",
            "CUTOFF: 10 - PRECISION: 0.1629967, RECALL: 0.1457959, MAP: 0.1042864, NDCG: 0.1481843, F1: 0.1539173, HIT_RATE: 1.6299669, RMSE: 0.8384327, \n",
            "CUTOFF: 20 - PRECISION: 0.1342632, RECALL: 0.2287448, MAP: 0.0969559, NDCG: 0.1929461, F1: 0.1692085, HIT_RATE: 2.6852649, RMSE: 0.8384327, \n",
            "CUTOFF: 50 - PRECISION: 0.0963344, RECALL: 0.3794229, MAP: 0.1031495, NDCG: 0.2590127, F1: 0.1536560, HIT_RATE: 4.8167219, RMSE: 0.8384327, \n",
            "CUTOFF: 80 - PRECISION: 0.0779925, RECALL: 0.4709111, MAP: 0.1097263, NDCG: 0.2940252, F1: 0.1338215, HIT_RATE: 6.2394040, RMSE: 0.8384327, \n",
            "CUTOFF: 100 - PRECISION: 0.0699040, RECALL: 0.5158182, MAP: 0.1130875, NDCG: 0.3103335, F1: 0.1231223, HIT_RATE: 6.9903974, RMSE: 0.8384327, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████      | 120/300 [25:02<13:21,  4.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 120. Total: 86.31 secs, 8.63 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.1906954, RECALL: 0.0896355, MAP: 0.1291611, NDCG: 0.1117705, F1: 0.1219493, HIT_RATE: 0.9534768, RMSE: 0.8278416, \n",
            "CUTOFF: 10 - PRECISION: 0.1668709, RECALL: 0.1503966, MAP: 0.1076572, NDCG: 0.1523990, F1: 0.1582060, HIT_RATE: 1.6687086, RMSE: 0.8278416, \n",
            "CUTOFF: 20 - PRECISION: 0.1376242, RECALL: 0.2348686, MAP: 0.1004655, NDCG: 0.1982436, F1: 0.1735529, HIT_RATE: 2.7524834, RMSE: 0.8278416, \n",
            "CUTOFF: 50 - PRECISION: 0.0988477, RECALL: 0.3882074, MAP: 0.1070779, NDCG: 0.2657936, F1: 0.1575732, HIT_RATE: 4.9423841, RMSE: 0.8278416, \n",
            "CUTOFF: 80 - PRECISION: 0.0799131, RECALL: 0.4809961, MAP: 0.1139575, NDCG: 0.3013409, F1: 0.1370556, HIT_RATE: 6.3930464, RMSE: 0.8278416, \n",
            "CUTOFF: 100 - PRECISION: 0.0716258, RECALL: 0.5260999, MAP: 0.1174516, NDCG: 0.3178547, F1: 0.1260857, HIT_RATE: 7.1625828, RMSE: 0.8278416, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 130/300 [27:09<12:29,  4.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 130. Total: 85.87 secs, 8.59 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.1938411, RECALL: 0.0916660, MAP: 0.1317155, NDCG: 0.1141929, F1: 0.1244707, HIT_RATE: 0.9692053, RMSE: 0.8185961, \n",
            "CUTOFF: 10 - PRECISION: 0.1708609, RECALL: 0.1550694, MAP: 0.1106681, NDCG: 0.1564012, F1: 0.1625826, HIT_RATE: 1.7086093, RMSE: 0.8185961, \n",
            "CUTOFF: 20 - PRECISION: 0.1398675, RECALL: 0.2390965, MAP: 0.1033016, NDCG: 0.2022137, F1: 0.1764909, HIT_RATE: 2.7973510, RMSE: 0.8185961, \n",
            "CUTOFF: 50 - PRECISION: 0.1009934, RECALL: 0.3964812, MAP: 0.1105466, NDCG: 0.2717188, F1: 0.1609810, HIT_RATE: 5.0496689, RMSE: 0.8185961, \n",
            "CUTOFF: 80 - PRECISION: 0.0815066, RECALL: 0.4891082, MAP: 0.1176316, NDCG: 0.3074437, F1: 0.1397284, HIT_RATE: 6.5205298, RMSE: 0.8185961, \n",
            "CUTOFF: 100 - PRECISION: 0.0730646, RECALL: 0.5359586, MAP: 0.1212726, NDCG: 0.3244638, F1: 0.1285980, HIT_RATE: 7.3064570, RMSE: 0.8185961, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|████▋     | 140/300 [29:17<11:44,  4.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 140. Total: 86.22 secs, 8.62 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.1973179, RECALL: 0.0932615, MAP: 0.1343344, NDCG: 0.1163630, F1: 0.1266584, HIT_RATE: 0.9865894, RMSE: 0.8107334, \n",
            "CUTOFF: 10 - PRECISION: 0.1736755, RECALL: 0.1578547, MAP: 0.1131836, NDCG: 0.1593584, F1: 0.1653876, HIT_RATE: 1.7367550, RMSE: 0.8107334, \n",
            "CUTOFF: 20 - PRECISION: 0.1424752, RECALL: 0.2457223, MAP: 0.1060169, NDCG: 0.2067900, F1: 0.1803686, HIT_RATE: 2.8495033, RMSE: 0.8107334, \n",
            "CUTOFF: 50 - PRECISION: 0.1027252, RECALL: 0.4036719, MAP: 0.1135464, NDCG: 0.2768303, F1: 0.1637737, HIT_RATE: 5.1362583, RMSE: 0.8107334, \n",
            "CUTOFF: 80 - PRECISION: 0.0829429, RECALL: 0.4967552, MAP: 0.1208780, NDCG: 0.3129046, F1: 0.1421509, HIT_RATE: 6.6354305, RMSE: 0.8107334, \n",
            "CUTOFF: 100 - PRECISION: 0.0742616, RECALL: 0.5433835, MAP: 0.1245872, NDCG: 0.3299542, F1: 0.1306657, HIT_RATE: 7.4261589, RMSE: 0.8107334, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 150/300 [31:24<10:58,  4.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 150. Total: 85.56 secs, 8.56 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2003642, RECALL: 0.0950777, MAP: 0.1362167, NDCG: 0.1185479, F1: 0.1289605, HIT_RATE: 1.0018212, RMSE: 0.8041891, \n",
            "CUTOFF: 10 - PRECISION: 0.1755298, RECALL: 0.1610483, MAP: 0.1148183, NDCG: 0.1622537, F1: 0.1679775, HIT_RATE: 1.7552980, RMSE: 0.8041891, \n",
            "CUTOFF: 20 - PRECISION: 0.1444454, RECALL: 0.2501502, MAP: 0.1081631, NDCG: 0.2103342, F1: 0.1831396, HIT_RATE: 2.8889073, RMSE: 0.8041891, \n",
            "CUTOFF: 50 - PRECISION: 0.1041689, RECALL: 0.4082717, MAP: 0.1161036, NDCG: 0.2809235, F1: 0.1659869, HIT_RATE: 5.2084437, RMSE: 0.8041891, \n",
            "CUTOFF: 80 - PRECISION: 0.0841163, RECALL: 0.5030277, MAP: 0.1236667, NDCG: 0.3176306, F1: 0.1441310, HIT_RATE: 6.7293046, RMSE: 0.8041891, \n",
            "CUTOFF: 100 - PRECISION: 0.0753195, RECALL: 0.5501894, MAP: 0.1274759, NDCG: 0.3349075, F1: 0.1325001, HIT_RATE: 7.5319536, RMSE: 0.8041891, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 160/300 [33:30<10:16,  4.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 160. Total: 85.72 secs, 8.57 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2026159, RECALL: 0.0966303, MAP: 0.1380689, NDCG: 0.1202523, F1: 0.1308543, HIT_RATE: 1.0130795, RMSE: 0.7989040, \n",
            "CUTOFF: 10 - PRECISION: 0.1771854, RECALL: 0.1629224, MAP: 0.1166879, NDCG: 0.1642008, F1: 0.1697549, HIT_RATE: 1.7718543, RMSE: 0.7989040, \n",
            "CUTOFF: 20 - PRECISION: 0.1463659, RECALL: 0.2531750, MAP: 0.1101666, NDCG: 0.2131486, F1: 0.1854938, HIT_RATE: 2.9273179, RMSE: 0.7989040, \n",
            "CUTOFF: 50 - PRECISION: 0.1054868, RECALL: 0.4137680, MAP: 0.1183706, NDCG: 0.2846718, F1: 0.1681142, HIT_RATE: 5.2743377, RMSE: 0.7989040, \n",
            "CUTOFF: 80 - PRECISION: 0.0851200, RECALL: 0.5079959, MAP: 0.1260583, NDCG: 0.3214487, F1: 0.1458083, HIT_RATE: 6.8096026, RMSE: 0.7989040, \n",
            "CUTOFF: 100 - PRECISION: 0.0761772, RECALL: 0.5548172, MAP: 0.1299428, NDCG: 0.3386755, F1: 0.1339612, HIT_RATE: 7.6177152, RMSE: 0.7989040, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 170/300 [35:37<09:32,  4.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 170. Total: 85.89 secs, 8.59 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2055298, RECALL: 0.0982984, MAP: 0.1400440, NDCG: 0.1220329, F1: 0.1329913, HIT_RATE: 1.0276490, RMSE: 0.7947329, \n",
            "CUTOFF: 10 - PRECISION: 0.1788079, RECALL: 0.1645880, MAP: 0.1181618, NDCG: 0.1659960, F1: 0.1714036, HIT_RATE: 1.7880795, RMSE: 0.7947329, \n",
            "CUTOFF: 20 - PRECISION: 0.1479636, RECALL: 0.2560423, MAP: 0.1118042, NDCG: 0.2156530, F1: 0.1875465, HIT_RATE: 2.9592715, RMSE: 0.7947329, \n",
            "CUTOFF: 50 - PRECISION: 0.1066093, RECALL: 0.4182155, MAP: 0.1201837, NDCG: 0.2878475, F1: 0.1699068, HIT_RATE: 5.3304636, RMSE: 0.7947329, \n",
            "CUTOFF: 80 - PRECISION: 0.0858899, RECALL: 0.5115205, MAP: 0.1279777, NDCG: 0.3245132, F1: 0.1470830, HIT_RATE: 6.8711921, RMSE: 0.7947329, \n",
            "CUTOFF: 100 - PRECISION: 0.0769272, RECALL: 0.5586719, MAP: 0.1319646, NDCG: 0.3419263, F1: 0.1352332, HIT_RATE: 7.6927152, RMSE: 0.7947329, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 60%|██████    | 180/300 [37:45<08:46,  4.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 180. Total: 85.32 secs, 8.53 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2066225, RECALL: 0.0989934, MAP: 0.1407073, NDCG: 0.1227724, F1: 0.1338560, HIT_RATE: 1.0331126, RMSE: 0.7915090, \n",
            "CUTOFF: 10 - PRECISION: 0.1797185, RECALL: 0.1661646, MAP: 0.1186736, NDCG: 0.1672241, F1: 0.1726760, HIT_RATE: 1.7971854, RMSE: 0.7915090, \n",
            "CUTOFF: 20 - PRECISION: 0.1490977, RECALL: 0.2581552, MAP: 0.1127396, NDCG: 0.2172278, F1: 0.1890243, HIT_RATE: 2.9819536, RMSE: 0.7915090, \n",
            "CUTOFF: 50 - PRECISION: 0.1075828, RECALL: 0.4218037, MAP: 0.1214427, NDCG: 0.2901804, F1: 0.1714393, HIT_RATE: 5.3791391, RMSE: 0.7915090, \n",
            "CUTOFF: 80 - PRECISION: 0.0866163, RECALL: 0.5147298, MAP: 0.1293417, NDCG: 0.3268656, F1: 0.1482806, HIT_RATE: 6.9293046, RMSE: 0.7915090, \n",
            "CUTOFF: 100 - PRECISION: 0.0775596, RECALL: 0.5618807, MAP: 0.1333910, NDCG: 0.3442952, F1: 0.1363043, HIT_RATE: 7.7559603, RMSE: 0.7915090, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 190/300 [39:50<07:58,  4.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 190. Total: 84.62 secs, 8.46 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2075166, RECALL: 0.1001084, MAP: 0.1415198, NDCG: 0.1240494, F1: 0.1350616, HIT_RATE: 1.0375828, RMSE: 0.7891101, \n",
            "CUTOFF: 10 - PRECISION: 0.1812417, RECALL: 0.1675438, MAP: 0.1199349, NDCG: 0.1688324, F1: 0.1741238, HIT_RATE: 1.8124172, RMSE: 0.7891101, \n",
            "CUTOFF: 20 - PRECISION: 0.1501904, RECALL: 0.2600969, MAP: 0.1139501, NDCG: 0.2190374, F1: 0.1904230, HIT_RATE: 3.0038079, RMSE: 0.7891101, \n",
            "CUTOFF: 50 - PRECISION: 0.1082649, RECALL: 0.4236638, MAP: 0.1228605, NDCG: 0.2922190, F1: 0.1724589, HIT_RATE: 5.4132450, RMSE: 0.7891101, \n",
            "CUTOFF: 80 - PRECISION: 0.0871875, RECALL: 0.5168191, MAP: 0.1308536, NDCG: 0.3290461, F1: 0.1492042, HIT_RATE: 6.9750000, RMSE: 0.7891101, \n",
            "CUTOFF: 100 - PRECISION: 0.0780712, RECALL: 0.5645164, MAP: 0.1349740, NDCG: 0.3466563, F1: 0.1371719, HIT_RATE: 7.8071192, RMSE: 0.7891101, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 200/300 [41:55<07:11,  4.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 200. Total: 84.46 secs, 8.45 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2087748, RECALL: 0.1013942, MAP: 0.1421302, NDCG: 0.1250344, F1: 0.1364969, HIT_RATE: 1.0438742, RMSE: 0.7874299, \n",
            "CUTOFF: 10 - PRECISION: 0.1812417, RECALL: 0.1675747, MAP: 0.1202595, NDCG: 0.1691429, F1: 0.1741405, HIT_RATE: 1.8124172, RMSE: 0.7874299, \n",
            "CUTOFF: 20 - PRECISION: 0.1511175, RECALL: 0.2613011, MAP: 0.1146680, NDCG: 0.2200521, F1: 0.1914908, HIT_RATE: 3.0223510, RMSE: 0.7874299, \n",
            "CUTOFF: 50 - PRECISION: 0.1088907, RECALL: 0.4251390, MAP: 0.1236736, NDCG: 0.2935415, F1: 0.1733750, HIT_RATE: 5.4445364, RMSE: 0.7874299, \n",
            "CUTOFF: 80 - PRECISION: 0.0877877, RECALL: 0.5191535, MAP: 0.1318087, NDCG: 0.3306689, F1: 0.1501802, HIT_RATE: 7.0230132, RMSE: 0.7874299, \n",
            "CUTOFF: 100 - PRECISION: 0.0785099, RECALL: 0.5646715, MAP: 0.1359077, NDCG: 0.3478446, F1: 0.1378532, HIT_RATE: 7.8509934, RMSE: 0.7874299, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 210/300 [44:01<06:34,  4.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 210. Total: 85.50 secs, 8.55 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2090066, RECALL: 0.1013219, MAP: 0.1422734, NDCG: 0.1251265, F1: 0.1364809, HIT_RATE: 1.0450331, RMSE: 0.7863868, \n",
            "CUTOFF: 10 - PRECISION: 0.1811755, RECALL: 0.1679225, MAP: 0.1203847, NDCG: 0.1694450, F1: 0.1742974, HIT_RATE: 1.8117550, RMSE: 0.7863868, \n",
            "CUTOFF: 20 - PRECISION: 0.1512500, RECALL: 0.2611983, MAP: 0.1149551, NDCG: 0.2202974, F1: 0.1915694, HIT_RATE: 3.0250000, RMSE: 0.7863868, \n",
            "CUTOFF: 50 - PRECISION: 0.1093675, RECALL: 0.4251626, MAP: 0.1242742, NDCG: 0.2942224, F1: 0.1739808, HIT_RATE: 5.4683775, RMSE: 0.7863868, \n",
            "CUTOFF: 80 - PRECISION: 0.0881685, RECALL: 0.5201808, MAP: 0.1325007, NDCG: 0.3316161, F1: 0.1507803, HIT_RATE: 7.0534768, RMSE: 0.7863868, \n",
            "CUTOFF: 100 - PRECISION: 0.0788162, RECALL: 0.5656156, MAP: 0.1366040, NDCG: 0.3487429, F1: 0.1383535, HIT_RATE: 7.8816225, RMSE: 0.7863868, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 220/300 [46:07<05:50,  4.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 220. Total: 85.03 secs, 8.50 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2105629, RECALL: 0.1016200, MAP: 0.1429079, NDCG: 0.1256855, F1: 0.1370825, HIT_RATE: 1.0528146, RMSE: 0.7859157, \n",
            "CUTOFF: 10 - PRECISION: 0.1816060, RECALL: 0.1683984, MAP: 0.1207515, NDCG: 0.1699699, F1: 0.1747530, HIT_RATE: 1.8160596, RMSE: 0.7859157, \n",
            "CUTOFF: 20 - PRECISION: 0.1515811, RECALL: 0.2619226, MAP: 0.1153624, NDCG: 0.2209353, F1: 0.1920298, HIT_RATE: 3.0316225, RMSE: 0.7859157, \n",
            "CUTOFF: 50 - PRECISION: 0.1096755, RECALL: 0.4249117, MAP: 0.1247800, NDCG: 0.2947466, F1: 0.1743491, HIT_RATE: 5.4837748, RMSE: 0.7859157, \n",
            "CUTOFF: 80 - PRECISION: 0.0884230, RECALL: 0.5202559, MAP: 0.1330597, NDCG: 0.3322690, F1: 0.1511555, HIT_RATE: 7.0738411, RMSE: 0.7859157, \n",
            "CUTOFF: 100 - PRECISION: 0.0791341, RECALL: 0.5668372, MAP: 0.1372395, NDCG: 0.3497111, F1: 0.1388797, HIT_RATE: 7.9134106, RMSE: 0.7859157, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 77%|███████▋  | 230/300 [48:14<05:08,  4.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 230. Total: 85.90 secs, 8.59 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2093377, RECALL: 0.1011787, MAP: 0.1424549, NDCG: 0.1253741, F1: 0.1364213, HIT_RATE: 1.0466887, RMSE: 0.7859333, \n",
            "CUTOFF: 10 - PRECISION: 0.1820033, RECALL: 0.1684154, MAP: 0.1208092, NDCG: 0.1701955, F1: 0.1749459, HIT_RATE: 1.8200331, RMSE: 0.7859333, \n",
            "CUTOFF: 20 - PRECISION: 0.1521026, RECALL: 0.2626194, MAP: 0.1155718, NDCG: 0.2214232, F1: 0.1926356, HIT_RATE: 3.0420530, RMSE: 0.7859333, \n",
            "CUTOFF: 50 - PRECISION: 0.1098411, RECALL: 0.4249362, MAP: 0.1250157, NDCG: 0.2949624, F1: 0.1745603, HIT_RATE: 5.4920530, RMSE: 0.7859333, \n",
            "CUTOFF: 80 - PRECISION: 0.0885803, RECALL: 0.5187651, MAP: 0.1333284, NDCG: 0.3322398, F1: 0.1513220, HIT_RATE: 7.0864238, RMSE: 0.7859333, \n",
            "CUTOFF: 100 - PRECISION: 0.0792632, RECALL: 0.5652140, MAP: 0.1375049, NDCG: 0.3496437, F1: 0.1390296, HIT_RATE: 7.9263245, RMSE: 0.7859333, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 80%|████████  | 240/300 [50:21<04:23,  4.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 240. Total: 85.46 secs, 8.55 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2084106, RECALL: 0.1010032, MAP: 0.1418555, NDCG: 0.1251013, F1: 0.1360647, HIT_RATE: 1.0420530, RMSE: 0.7863950, \n",
            "CUTOFF: 10 - PRECISION: 0.1814901, RECALL: 0.1675836, MAP: 0.1203116, NDCG: 0.1696889, F1: 0.1742599, HIT_RATE: 1.8149007, RMSE: 0.7863950, \n",
            "CUTOFF: 20 - PRECISION: 0.1523758, RECALL: 0.2621984, MAP: 0.1154637, NDCG: 0.2211766, F1: 0.1927409, HIT_RATE: 3.0475166, RMSE: 0.7863950, \n",
            "CUTOFF: 50 - PRECISION: 0.1098907, RECALL: 0.4236006, MAP: 0.1248408, NDCG: 0.2944824, F1: 0.1745100, HIT_RATE: 5.4945364, RMSE: 0.7863950, \n",
            "CUTOFF: 80 - PRECISION: 0.0886320, RECALL: 0.5179480, MAP: 0.1331951, NDCG: 0.3318669, F1: 0.1513627, HIT_RATE: 7.0905629, RMSE: 0.7863950, \n",
            "CUTOFF: 100 - PRECISION: 0.0792732, RECALL: 0.5630059, MAP: 0.1373556, NDCG: 0.3489403, F1: 0.1389778, HIT_RATE: 7.9273179, RMSE: 0.7863950, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 250/300 [52:28<03:40,  4.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 250. Total: 85.86 secs, 8.59 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2082781, RECALL: 0.1007745, MAP: 0.1413318, NDCG: 0.1249343, F1: 0.1358288, HIT_RATE: 1.0413907, RMSE: 0.7872486, \n",
            "CUTOFF: 10 - PRECISION: 0.1819536, RECALL: 0.1674915, MAP: 0.1202372, NDCG: 0.1696423, F1: 0.1744233, HIT_RATE: 1.8195364, RMSE: 0.7872486, \n",
            "CUTOFF: 20 - PRECISION: 0.1523096, RECALL: 0.2612067, MAP: 0.1152538, NDCG: 0.2207575, F1: 0.1924194, HIT_RATE: 3.0461921, RMSE: 0.7872486, \n",
            "CUTOFF: 50 - PRECISION: 0.1098013, RECALL: 0.4225395, MAP: 0.1245929, NDCG: 0.2939215, F1: 0.1743071, HIT_RATE: 5.4900662, RMSE: 0.7872486, \n",
            "CUTOFF: 80 - PRECISION: 0.0886900, RECALL: 0.5169161, MAP: 0.1330221, NDCG: 0.3314203, F1: 0.1514030, HIT_RATE: 7.0951987, RMSE: 0.7872486, \n",
            "CUTOFF: 100 - PRECISION: 0.0792036, RECALL: 0.5606629, MAP: 0.1371091, NDCG: 0.3481199, F1: 0.1387994, HIT_RATE: 7.9203642, RMSE: 0.7872486, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 87%|████████▋ | 260/300 [54:36<02:57,  4.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 260. Total: 86.35 secs, 8.64 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2075497, RECALL: 0.1007511, MAP: 0.1404011, NDCG: 0.1245296, F1: 0.1356524, HIT_RATE: 1.0377483, RMSE: 0.7884500, \n",
            "CUTOFF: 10 - PRECISION: 0.1812252, RECALL: 0.1664341, MAP: 0.1194328, NDCG: 0.1687121, F1: 0.1735150, HIT_RATE: 1.8122517, RMSE: 0.7884500, \n",
            "CUTOFF: 20 - PRECISION: 0.1515315, RECALL: 0.2590846, MAP: 0.1143994, NDCG: 0.2193820, F1: 0.1912223, HIT_RATE: 3.0306291, RMSE: 0.7884500, \n",
            "CUTOFF: 50 - PRECISION: 0.1095728, RECALL: 0.4205195, MAP: 0.1238337, NDCG: 0.2926262, F1: 0.1738471, HIT_RATE: 5.4786424, RMSE: 0.7884500, \n",
            "CUTOFF: 80 - PRECISION: 0.0885886, RECALL: 0.5153391, MAP: 0.1322846, NDCG: 0.3302410, F1: 0.1511875, HIT_RATE: 7.0870861, RMSE: 0.7884500, \n",
            "CUTOFF: 100 - PRECISION: 0.0791192, RECALL: 0.5579830, MAP: 0.1363260, NDCG: 0.3467164, F1: 0.1385874, HIT_RATE: 7.9119205, RMSE: 0.7884500, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 270/300 [56:43<02:12,  4.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 270. Total: 86.36 secs, 8.64 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2068874, RECALL: 0.1001649, MAP: 0.1401194, NDCG: 0.1241201, F1: 0.1349793, HIT_RATE: 1.0344371, RMSE: 0.7899487, \n",
            "CUTOFF: 10 - PRECISION: 0.1800166, RECALL: 0.1650617, MAP: 0.1188253, NDCG: 0.1677447, F1: 0.1722151, HIT_RATE: 1.8001656, RMSE: 0.7899487, \n",
            "CUTOFF: 20 - PRECISION: 0.1509189, RECALL: 0.2570317, MAP: 0.1138660, NDCG: 0.2182594, F1: 0.1901747, HIT_RATE: 3.0183775, RMSE: 0.7899487, \n",
            "CUTOFF: 50 - PRECISION: 0.1092947, RECALL: 0.4182342, MAP: 0.1232159, NDCG: 0.2914115, F1: 0.1733015, HIT_RATE: 5.4647351, RMSE: 0.7899487, \n",
            "CUTOFF: 80 - PRECISION: 0.0883361, RECALL: 0.5113692, MAP: 0.1316228, NDCG: 0.3286000, F1: 0.1506485, HIT_RATE: 7.0668874, RMSE: 0.7899487, \n",
            "CUTOFF: 100 - PRECISION: 0.0789669, RECALL: 0.5550552, MAP: 0.1356902, NDCG: 0.3453369, F1: 0.1382633, HIT_RATE: 7.8966887, RMSE: 0.7899487, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 280/300 [58:51<01:28,  4.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 280. Total: 86.06 secs, 8.61 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2058278, RECALL: 0.0994284, MAP: 0.1392753, NDCG: 0.1235586, F1: 0.1340849, HIT_RATE: 1.0291391, RMSE: 0.7917016, \n",
            "CUTOFF: 10 - PRECISION: 0.1791556, RECALL: 0.1639394, MAP: 0.1180504, NDCG: 0.1668778, F1: 0.1712101, HIT_RATE: 1.7915563, RMSE: 0.7917016, \n",
            "CUTOFF: 20 - PRECISION: 0.1502566, RECALL: 0.2550986, MAP: 0.1130748, NDCG: 0.2171017, F1: 0.1891193, HIT_RATE: 3.0051325, RMSE: 0.7917016, \n",
            "CUTOFF: 50 - PRECISION: 0.1089603, RECALL: 0.4159485, MAP: 0.1224181, NDCG: 0.2900795, F1: 0.1726847, HIT_RATE: 5.4480132, RMSE: 0.7917016, \n",
            "CUTOFF: 80 - PRECISION: 0.0880546, RECALL: 0.5076737, MAP: 0.1307510, NDCG: 0.3268516, F1: 0.1500786, HIT_RATE: 7.0443709, RMSE: 0.7917016, \n",
            "CUTOFF: 100 - PRECISION: 0.0787053, RECALL: 0.5514772, MAP: 0.1347843, NDCG: 0.3435688, F1: 0.1377511, HIT_RATE: 7.8705298, RMSE: 0.7917016, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 97%|█████████▋| 290/300 [1:00:58<00:44,  4.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 290. Total: 86.25 secs, 8.62 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2031126, RECALL: 0.0978055, MAP: 0.1376375, NDCG: 0.1216951, F1: 0.1320328, HIT_RATE: 1.0155629, RMSE: 0.7936658, \n",
            "CUTOFF: 10 - PRECISION: 0.1779967, RECALL: 0.1625929, MAP: 0.1168769, NDCG: 0.1652689, F1: 0.1699465, HIT_RATE: 1.7799669, RMSE: 0.7936658, \n",
            "CUTOFF: 20 - PRECISION: 0.1495116, RECALL: 0.2532338, MAP: 0.1119034, NDCG: 0.2152407, F1: 0.1880165, HIT_RATE: 2.9902318, RMSE: 0.7936658, \n",
            "CUTOFF: 50 - PRECISION: 0.1083874, RECALL: 0.4128285, MAP: 0.1210575, NDCG: 0.2877304, F1: 0.1716963, HIT_RATE: 5.4193709, RMSE: 0.7936658, \n",
            "CUTOFF: 80 - PRECISION: 0.0877049, RECALL: 0.5032417, MAP: 0.1293576, NDCG: 0.3242348, F1: 0.1493765, HIT_RATE: 7.0163907, RMSE: 0.7936658, \n",
            "CUTOFF: 100 - PRECISION: 0.0783940, RECALL: 0.5475052, MAP: 0.1333506, NDCG: 0.3409824, F1: 0.1371503, HIT_RATE: 7.8394040, RMSE: 0.7936658, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 300/300 [1:03:06<00:00,  4.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch : 300. Total: 86.47 secs, 8.65 secs/epoch.\n",
            "CUTOFF: 5 - PRECISION: 0.2004305, RECALL: 0.0963719, MAP: 0.1360153, NDCG: 0.1201990, F1: 0.1301598, HIT_RATE: 1.0021523, RMSE: 0.7958023, \n",
            "CUTOFF: 10 - PRECISION: 0.1765894, RECALL: 0.1611522, MAP: 0.1157812, NDCG: 0.1638546, F1: 0.1685180, HIT_RATE: 1.7658940, RMSE: 0.7958023, \n",
            "CUTOFF: 20 - PRECISION: 0.1485430, RECALL: 0.2514688, MAP: 0.1108218, NDCG: 0.2135729, F1: 0.1867642, HIT_RATE: 2.9708609, RMSE: 0.7958023, \n",
            "CUTOFF: 50 - PRECISION: 0.1079570, RECALL: 0.4098707, MAP: 0.1199084, NDCG: 0.2856788, F1: 0.1709001, HIT_RATE: 5.3978477, RMSE: 0.7958023, \n",
            "CUTOFF: 80 - PRECISION: 0.0872517, RECALL: 0.4989942, MAP: 0.1280419, NDCG: 0.3216950, F1: 0.1485318, HIT_RATE: 6.9801325, RMSE: 0.7958023, \n",
            "CUTOFF: 100 - PRECISION: 0.0780298, RECALL: 0.5427726, MAP: 0.1320127, NDCG: 0.3383155, F1: 0.1364442, HIT_RATE: 7.8029801, RMSE: 0.7958023, \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "301it [1:04:30, 12.90s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "301"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gan = GANMF(URM_train, mode='user')\n",
        "evaluatorValidation = EvaluatorHoldout(URM_validation,[5,10,20,50,80,100],exclude_seen=np.bool_(True))\n",
        "gan.fit(num_factors=250,\n",
        "        emb_dim=461,\n",
        "        d_reg=0.0001,\n",
        "        g_reg=0,\n",
        "        epochs=300,\n",
        "        batch_size=512,\n",
        "        g_lr=0.0001,\n",
        "        d_lr=0.0001,\n",
        "        d_steps=1,\n",
        "        g_steps=1,\n",
        "        recon_coefficient=0.1728565040890659,\n",
        "        m=10,\n",
        "        allow_worse=5,\n",
        "        freq=5,\n",
        "        validation_evaluator=evaluatorValidation,\n",
        "        sample_every=10,\n",
        "        validation_set=URM_validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2uG-fqg4K_H",
        "outputId": "3bed897d-49f5-49d6-9e06-076dd7dbb1a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-6ceb33196298>:90: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  usersToEvaluate_mask = np.zeros(self.n_users, dtype=np.bool)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUTOFF: 5 - PRECISION: 0.2365563, RECALL: 0.0996637, MAP: 0.1557893, NDCG: 0.1335228, F1: 0.1402420, HIT_RATE: 1.1827815, RMSE: 0.7959542, \n",
            "CUTOFF: 10 - PRECISION: 0.2035430, RECALL: 0.1629253, MAP: 0.1278672, NDCG: 0.1791633, F1: 0.1809832, HIT_RATE: 2.0354305, RMSE: 0.7959542, \n",
            "CUTOFF: 20 - PRECISION: 0.1691639, RECALL: 0.2550325, MAP: 0.1208024, NDCG: 0.2327748, F1: 0.2034072, HIT_RATE: 3.3832781, RMSE: 0.7959542, \n",
            "CUTOFF: 50 - PRECISION: 0.1210132, RECALL: 0.4128077, MAP: 0.1306930, NDCG: 0.3088916, F1: 0.1871609, HIT_RATE: 6.0506623, RMSE: 0.7959542, \n",
            "CUTOFF: 80 - PRECISION: 0.0969578, RECALL: 0.5016631, MAP: 0.1393060, NDCG: 0.3465405, F1: 0.1625073, HIT_RATE: 7.7566225, RMSE: 0.7959542, \n",
            "CUTOFF: 100 - PRECISION: 0.0862351, RECALL: 0.5438527, MAP: 0.1435142, NDCG: 0.3634732, F1: 0.1488656, HIT_RATE: 8.6235099, RMSE: 0.7959542, \n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluator = EvaluatorHoldout(URM_test, [5,10,20,50,80,100], exclude_seen=True)\n",
        "results_dic, results_run_string = evaluator.evaluateRecommender(gan)\n",
        "print(results_run_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaUWNS7K4Fhh"
      },
      "outputs": [],
      "source": [
        "recommended_items_batch_list, scores_batch = gan.recommend(user_id_array=np.array([i for i in range(1,501)]),\n",
        "                                                                      remove_seen_flag=True,\n",
        "                                                                      cutoff = 500,\n",
        "                                                                      remove_top_pop_flag=False,\n",
        "                                                                      remove_CustomItems_flag=False,\n",
        "                                                                      return_scores = True\n",
        "                                                                     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koUT1zeLpNot"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "pd.DataFrame(recommended_items_batch_list).to_csv(\"generated.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_items_batch_list=np.array(recommended_items_batch_list)"
      ],
      "metadata": {
        "id": "QfBWhxh-NbBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# assume preds is of shape (3000, 500)\n",
        "recommended_items = []\n",
        "for i in range(6040):\n",
        "  a=[]\n",
        "  for j in range(3706):\n",
        "    try:\n",
        "      a.append(recommended_items_batch_list[i,j])\n",
        "    except:\n",
        "      a.append(0)\n",
        "  recommended_items.append(a)"
      ],
      "metadata": {
        "id": "0n4IIbOgPhkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(recommended_items).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7sbLW_cNlD9",
        "outputId": "688e37be-f74a-4dc9-cbcb-31cacfefb193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6040, 3706)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_users = len(recommended_items)\n",
        "num_items = np.max(np.array(recommended_items))+1\n",
        "\n",
        "interaction_matrix = np.zeros((num_users, num_items))\n",
        "\n",
        "for user_id, recommended_items_list in enumerate(recommended_items):\n",
        "    interaction_matrix[user_id, recommended_items_list] = 1\n"
      ],
      "metadata": {
        "id": "4rARluNsQ73G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YsNVbiXJnR_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Assuming recommended_items_batch_list is a 2D numpy array\n",
        "sparse_matrix = csr_matrix(interaction_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdp2SuWjPYf9",
        "outputId": "0cceea47-34e1-4e94-afff-b7bf123ada43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6040, 3706)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvXW21wB2lpc"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import functools\n",
        "from jax import scipy as sp\n",
        "from jax import numpy as jnp\n",
        "from neural_tangents import stax\n",
        "\n",
        "a,b,kernel_fn=stax.serial(stax.Flatten(),\n",
        "    stax.Dense(1024,W_std=2*0.5,b_std=0.1,parameterization='ntk'),\n",
        "    stax.Relu(),\n",
        "    stax.Dense(num_items, W_std=2*0.5, b_std=0.1, parameterization='ntk'))\n",
        "kernel_fn=functools.partial(kernel_fn,get='ntk')\n",
        "@jax.jit\n",
        "def kernelized_rr(X_train, X_predict, reg):\n",
        "    K_train = kernel_fn(X_train, X_train)\n",
        "    K_predict = kernel_fn(X_predict, X_train)\n",
        "    K_reg = (K_train + jnp.abs(reg) * jnp.trace(K_train) * jnp.eye(K_train.shape[0]) / K_train.shape[0])     \n",
        "    return jnp.dot(K_predict, sp.linalg.solve(K_reg, X_train, assume_a='pos'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-52lX5VJui_"
      },
      "outputs": [],
      "source": [
        "train_x=sparse_matrix\n",
        "sample_user=jnp.array(sparse_matrix[sparse_matrix.getnnz(1)>0].todense())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40klzYrWJ4eh"
      },
      "outputs": [],
      "source": [
        "preds1=kernelized_rr(sample_user,(sparse_matrix).todense(),reg=5.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUJnj_LdLEFM",
        "outputId": "03d06c44-dca0-4c21-d78e-5b71bf43a112"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6040, 3706)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ],
      "source": [
        "preds1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwdoUWHqKLLK",
        "outputId": "08fe4614-bb50-419c-b7ba-f3cc960a0af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hit rate for top @100: 17.510289820905207\n",
            "ndcg @100: 0.15592148287128016\n"
          ]
        }
      ],
      "source": [
        "logits=np.array(preds1)\n",
        "train_positive_list = list(map(list, ret['train_positive_set']))\n",
        "for b in range(len(logits)):logits[b][train_positive_list[b]]=-float(1e6)\n",
        "indices = (-logits).argsort()[:, :100].tolist()\n",
        "hr=0\n",
        "for i in range(100):\n",
        "  for b in range(len(logits)):\n",
        "    num_pos = float(len((ret['val_positive_set']+ret['test_positive_set'])[b]))\n",
        "\n",
        "    hr += float(len(set(indices[b][:100]) &(ret['val_positive_set']+ret['test_positive_set'])[b])) / float(min(num_pos, 100))\n",
        "hr/=num_users\n",
        "print(\"hit rate for top @100:\",hr)\n",
        "dcg,idcg=0.0,0.0\n",
        "for i in range(len(logits)):\n",
        "  for at, pred in enumerate(indices[b][:100]):\n",
        "      if pred in (ret['test_positive_set'])[b]: \n",
        "          dcg += 1.0 / np.log2(at + 2)\n",
        "      if at < num_pos: \n",
        "          idcg += 1.0 / np.log2(at + 2)\n",
        "print('ndcg @100:',dcg/idcg)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "def get_item_propensity(A = 0.55, B = 1.5):\n",
        "    item_count = defaultdict(int)\n",
        "    for u, i, r in sparse_matrix: item_count[i] += 1\n",
        "    item_freq_map = item_count\n",
        "    item_freq = [ item_freq_map[i] for i in range(ret['num_items']) ]\n",
        "    num_instances = ret['num_interactions']\n",
        "\n",
        "    C = (np.log(num_instances)-1)*np.power(B+1, A)\n",
        "    wts = 1.0 + C*np.power(np.array(item_freq)+B, -A)\n",
        "    return np.ravel(wts)"
      ],
      "metadata": {
        "id": "DXzkjmzvSDQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDYtEUrM2YzJ"
      },
      "outputs": [],
      "source": [
        "!pip install neural_tangents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bifIxFVyJK9a",
        "outputId": "b82e5835-9209-47fc-f33e-925ae004bef9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<6040x3706 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 791718 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ret['train_matrix']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOHNoMlRpHXO"
      },
      "outputs": [],
      "source": [
        "train_x=ret['train_matrix']\n",
        "sample_user=jnp.array(ret['train_matrix'][ret['train_matrix'].getnnz(1)>0].todense())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rn1bJr2U2pYH"
      },
      "outputs": [],
      "source": [
        "preds=kernelized_rr(sample_user,(ret['train_matrix']).todense(),reg=5.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pajO_5E4LQFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb985db-dd74-4062-a3c0-374b90099816"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6040, 3706)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg3zs6ii2wfB"
      },
      "outputs": [],
      "source": [
        "logits=np.array(preds)\n",
        "train_positive_list = list(map(list, ret['train_positive_set']))\n",
        "for b in range(len(logits)):logits[b][train_positive_list[b]]=-float(1e6)\n",
        "indices = (-logits).argsort()[:, :100].tolist()\n",
        "hr=0\n",
        "for i in range(100):\n",
        "  for b in range(len(logits)):\n",
        "    num_pos = float(len((ret['val_positive_set']+ret['test_positive_set'])[b]))\n",
        "\n",
        "    hr += float(len(set(indices[b][:100]) &(ret['val_positive_set']+ret['test_positive_set'])[b])) / float(min(num_pos, 100))\n",
        "hr/=num_users\n",
        "print(\"hit rate for top @100:\",hr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glkkfFCK20Nj"
      },
      "outputs": [],
      "source": [
        "dcg,idcg=0.0,0.0\n",
        "for i in range(len(logits)):\n",
        "  for at, pred in enumerate(indices[b][:100]):\n",
        "      if pred in (ret['test_positive_set'])[b]: \n",
        "          dcg += 1.0 / np.log2(at + 2)\n",
        "      if at < num_pos: \n",
        "          idcg += 1.0 / np.log2(at + 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX6TNA8X24LU",
        "outputId": "7e624be0-2f4e-401d-af29-05fba7bbf72f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ndcg @100: 0.4433405800945249\n"
          ]
        }
      ],
      "source": [
        "print('ndcg @100:',dcg/idcg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TLPwYTLGgFu"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "from numba import jit, float64\n",
        "\n",
        "INF = float(1e6)\n",
        "\n",
        "def evaluate( kernelized_rr_forward, data, item_propensity, train_x, topk = [ 10, 100 ], test_set_eval = False):\n",
        "    preds, y_binary, metrics = [], [], {}\n",
        "    for kind in [ 'HR', 'NDCG', 'PSP' ]:\n",
        "        for k in topk: \n",
        "            metrics['{}@{}'.format(kind, k)] = 0.0\n",
        "\n",
        "    train_positive_list = list(map(list, ret['train_positive_set']))\n",
        "    if test_set_eval:\n",
        "        for u in range(len(train_positive_list)): train_positive_list[u] += list(ret['val_positive_set'][u])\n",
        "\n",
        "    eval_context = ret['train_matrix']\n",
        "    if test_set_eval: eval_context += ret['val_matrix']\n",
        "\n",
        "    to_predict = ret['val_positive_set']\n",
        "    if test_set_eval: to_predict = ret['test_positive_set']\n",
        "\n",
        "    bsz = 2000 \n",
        "    for i in range(0, ret['num_users'], bsz):\n",
        "        temp_preds = kernelized_rr_forward(train_x, eval_context[i:i+bsz].todense(), reg = 5.0)\n",
        "        \n",
        "        metrics, temp_preds, temp_y = evaluate_batch(\n",
        "            ret['negatives'][i:i+bsz], np.array(temp_preds), \n",
        "            train_positive_list[i:i+bsz], to_predict[i:i+bsz], item_propensity, \n",
        "            topk, metrics\n",
        "        )\n",
        "        \n",
        "        preds += temp_preds\n",
        "        y_binary += temp_y\n",
        "\n",
        "    y_binary, preds = np.array(y_binary), np.array(preds)\n",
        "    if (True not in np.isnan(y_binary)) and (True not in np.isnan(preds)):\n",
        "        metrics['AUC'] = round(fast_auc(y_binary, preds), 4)\n",
        "\n",
        "    for kind in [ 'HR', 'NDCG', 'PSP' ]:\n",
        "        for k in topk: \n",
        "            metrics['{}@{}'.format(kind, k)] = round(\n",
        "                float(100.0 * metrics['{}@{}'.format(kind, k)]) / ret['num_users'], 4\n",
        "            )\n",
        "\n",
        "    metrics['num_users'] = int(train_x.shape[0])\n",
        "    metrics['num_interactions'] = int(jnp.count_nonzero(train_x.astype(np.int8)))\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def evaluate_batch(auc_negatives, logits, train_positive, test_positive_set, item_propensity, topk, metrics, train_metrics = False):\n",
        "    # AUC Stuff\n",
        "    temp_preds, temp_y = [], []\n",
        "    for b in range(len(logits)):\n",
        "        temp_preds += np.take(logits[b], np.array(list(test_positive_set[b]))).tolist()\n",
        "        temp_y += [ 1.0 for _ in range(len(test_positive_set[b])) ]\n",
        "\n",
        "        temp_preds += np.take(logits[b], auc_negatives[b]).tolist()\n",
        "        temp_y += [ 0.0 for _ in range(len(auc_negatives[b])) ]\n",
        "\n",
        "    # Marking train-set consumed items as negative INF\n",
        "    for b in range(len(logits)): logits[b][ train_positive[b] ] = -INF\n",
        "\n",
        "    indices = (-logits).argsort()[:, :max(topk)].tolist()\n",
        "\n",
        "    for k in topk: \n",
        "        for b in range(len(logits)):\n",
        "            num_pos = float(len(test_positive_set[b]))\n",
        "\n",
        "            metrics['HR@{}'.format(k)] += float(len(set(indices[b][:k]) & test_positive_set[b])) / float(min(num_pos, k))\n",
        "\n",
        "            test_positive_sorted_psp = sorted([ item_propensity[x] for x in test_positive_set[b] ])[::-1]\n",
        "\n",
        "            dcg, idcg, psp, max_psp = 0.0, 0.0, 0.0, 0.0\n",
        "            for at, pred in enumerate(indices[b][:k]):\n",
        "                if pred in test_positive_set[b]: \n",
        "                    dcg += 1.0 / np.log2(at + 2)\n",
        "                    psp += float(item_propensity[pred]) / float(min(num_pos, k))\n",
        "                if at < num_pos: \n",
        "                    idcg += 1.0 / np.log2(at + 2)\n",
        "                    max_psp += test_positive_sorted_psp[at]\n",
        "\n",
        "            metrics['NDCG@{}'.format(k)] += dcg / idcg\n",
        "            metrics['PSP@{}'.format(k)] += psp / max_psp\n",
        "\n",
        "    return metrics, temp_preds, temp_y\n",
        "\n",
        "@jit(float64(float64[:], float64[:]))\n",
        "def fast_auc(y_true, y_prob):\n",
        "    y_true = y_true[np.argsort(y_prob)]\n",
        "    nfalse, auc = 0, 0\n",
        "    for i in range(len(y_true)):\n",
        "        nfalse += (1 - y_true[i])\n",
        "        auc += y_true[i] * nfalse\n",
        "    return auc / (nfalse * (len(y_true) - nfalse))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoY3gBkkAwOU"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "def get_item_propensity(A = 0.55, B = 1.5):\n",
        "    item_count = defaultdict(int)\n",
        "    for u, i, r in ret['train']: item_count[i] += 1\n",
        "    item_freq_map = item_count\n",
        "    item_freq = [ item_freq_map[i] for i in range(ret['num_items']) ]\n",
        "    num_instances = ret['num_interactions']\n",
        "\n",
        "    C = (np.log(num_instances)-1)*np.power(B+1, A)\n",
        "    wts = 1.0 + C*np.power(np.array(item_freq)+B, -A)\n",
        "    return np.ravel(wts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo500cD8_YaE"
      },
      "outputs": [],
      "source": [
        "topk=[10,100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArNoLxKW_upD"
      },
      "outputs": [],
      "source": [
        "train_positive_list = list(map(list, ret['train_positive_set']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ravytbFmAmtr"
      },
      "outputs": [],
      "source": [
        "item_propensity = get_item_propensity()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY8biOZAHP2-"
      },
      "outputs": [],
      "source": [
        "test_metrics = evaluate( kernelized_rr, data, item_propensity, sample_user, test_set_eval = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W_JICb_Iiw-",
        "outputId": "61575b9e-7bf9-4522-a71d-d8e7c6fea493"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'HR@10': 32.4454,\n",
              " 'HR@100': 60.525,\n",
              " 'NDCG@10': 33.6757,\n",
              " 'NDCG@100': 43.0133,\n",
              " 'PSP@10': 3.3146,\n",
              " 'PSP@100': 6.6373,\n",
              " 'AUC': 0.9461,\n",
              " 'num_users': 6040,\n",
              " 'num_interactions': 791718}"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics1 = evaluate( kernelized_rr, data, item_propensity, sample_user, test_set_eval = True)"
      ],
      "metadata": {
        "id": "Wgp88NlwSTmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_metrics1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCHd0tZlSeOJ",
        "outputId": "cf52678c-3f04-4c66-e9ce-83aceb308f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'HR@10': 16.9743,\n",
              " 'HR@100': 45.9048,\n",
              " 'NDCG@10': 16.0648,\n",
              " 'NDCG@100': 27.4142,\n",
              " 'PSP@10': 1.8038,\n",
              " 'PSP@100': 4.9726,\n",
              " 'AUC': 0.923,\n",
              " 'num_users': 6040,\n",
              " 'num_interactions': 1504728}"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distiil-cf HR@10 = 20.1002 | HR@100 = 47.2420 | NDCG@10 = 17.8793 | NDCG@100 = 28.1907 | PSP@10 = 2.0012 | PSP@100 = 5.2494 | AUC = 0.9211 | num_users = 500.0000 (VAL)"
      ],
      "metadata": {
        "id": "ejEImg7UszRt"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}